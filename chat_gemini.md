Делаем систему подготовки требований с помощью ИИ.
1 этап подготовки требований: запрос на разработку.
Пользователь вводит запрос на разработку (здесь и далее - в веб-интерфейсе), отправляет его на сервер (n8n)
Сервер принимает, отправляет на уточнение в ИИ (модель выбирает пользователь) вместе с системным промптом, где описана задача по проверке,
ИИ проверяет запрос на неопределенности, возвращает JSON со статусом (есть неопределенности / нет неопределенностей) если есть неопределнности - включает вопросы к неопределенностям в тексте в формате массива объектов, которые содержат: id вопроса, точную цитату из текста запроса, вопрос, тип вопроса.
Сервер отправляет JSON в пользовательский интерфейс, где пользователь вводит ответы на вопросы и отправляет на сервер JSON с ответами на вопросы (тот же JSON, но в объект вопроса добавлен текст ответа), при этом должна быть проверка на то, все ответы заполнены, или нет (должны быть все заполнены, иначе не разрешать отправлять)
Сервер принимает JSON  с ответами и отправляет ИИ на проверку качества ответов: если есть ответы не по делу или некачественные, он должен добавить строку с замечаниями к ответам, и сервер должен вернуть ответы в пользовательский интерфейс, где пользователь должен увидеть отправленные ответы с замечаниями ИИ, и уточнить ответы (пользовательский интерфейс не должен принимать от пользователя ответы, если он их не изменил), и отправить обратно на сервер.
Сервер снова принимает, и проверяет качество ответов. Если проверка качества не прошла - снова возвращает пользователю, если проверка качества прошла, то сервер передает ответы ИИ для уточнения запроса на разработку на основании ответов пользователя.
ИИ генерирует уточненный запрос, и передает серверу, а сервер передает уточненный запрос в пользовательский интерфейс для ревизии пользователем.
Пользователь проверяет, и если необходимо - вносит правки, после чего отправляет проверенный запрос на сервер.
Сервер принимает, и передает ИИ для проверки на неопределенность, и если ИИ находит неопределенность, процесс устранения неопределенности повторяется. Если ИИ не находит неопределенность в уточненном запросе, то сервер сохраняет уточненный запрос на разработку.
Нужно сделать подробное описание процесса 1 этапа, в котором будет описано взаимодействие пользователя, пользовательского интерфейса, сервера, ИИ. Описать реализацию системы. Нужно проверить сначала этот запрос, если есть необходимость - задать уточняющие вопросы. Сервер - n8n, пользовательский интерфейс - статический сайт html+js+API, ИИ подключается к n8n по API.


Привет! Идея системы звучит очень логично и структурированно. Это классический итеративный подход к выявлению требований (Requirements Elicitation), автоматизированный через LLM. Использование n8n как оркестратора — отличное решение для гибкости логики.


Я проанализировал твой запрос. Логика процесса понятна, но для написания детального технического задания и схемы реализации есть несколько важных моментов, которые нужно уточнить.


Вот мои вопросы и уточнения перед тем, как я распишу полную реализацию:

1. Хранение состояния (State Management)

n8n по своей природе stateless (если не использовать специальные ноды памяти или БД).


Вопрос: Где хранится история переписки и текущий контекст (JSON с вопросами/ответами) между шагами?
Вариант А: Клиент (браузер) хранит всё у себя и каждый раз отправляет полный JSON («толстый клиент»).
Вариант Б: n8n сохраняет промежуточные этапы в базу данных (Postgres, Redis, Airtable и т.д.) и обменивается с клиентом только ID сессии и актуальными данными.
Почему это важно: Это определяет структуру API и безопасность данных. Рекомендую Вариант Б для надежности, но Вариант А проще в реализации.

2. Типы вопросов от ИИ

Ты упомянул
тип вопроса
 в структуре JSON.


Вопрос: Какие типы вопросов мы поддерживаем на фронтенде?
Только текстовое поле (
text
)?
Выбор из вариантов (
single-choice
,
multi-choice
)? (Тогда ИИ должен генерировать и варианты ответов).
Да/Нет (
boolean
)?

3. Логика проверки качества ответов

Пользователь ответил на 5 вопросов. 1 ответ плохой, 4 хороших.


Вопрос: Как мы возвращаем это пользователю?
Мы блокируем отправку всех ответов, пока он не исправит тот самый плохой?
Или мы принимаем хорошие, а плохой возвращаем на доработку?
Исходя из твоего описания: «пользовательский интерфейс не должен принимать от пользователя ответы, если он их не изменил». Это значит, блокируем всё, пока не исправит замечания. Верно?

4. «Тупик» в проверке качества (Escape Hatch)

ИИ может быть субъективен или «галлюцинировать», утверждая, что ответ некачественный, хотя пользователь дал максимум информации.


Вопрос: Предусмотрена ли кнопка «Отправить принудительно» или ограничение на количество циклов проверки (например, после 2-й неудачной проверки качества переводить на человека или пропускать дальше)? Или мы жестко требуем удовлетворить ИИ?

5. Финальное сохранение

Вопрос: Куда сервер сохраняет итоговый уточненный запрос? (Отправляет на email, сохраняет в Google Doc, в Jira, в базу данных?).

6. Выбор модели

Вопрос: Пользователь выбирает модель (GPT-4, Claude 3.5, Local LLM) один раз при старте, и этот выбор прокидывается во все последующие запросы к n8n?


Как только ты ответишь на эти вопросы (или скажешь, какие варианты выбрать на моё усмотрение), я составлю подробное описание процесса, структуру JSON-объектов на каждом этапе и логику работы n8n.

это все вопросы?


Да, это основные вопросы, которые влияют на архитектуру. Есть еще один небольшой момент касательно формата результата, который стоит прояснить, чтобы я мог правильно описать промпты.


Добавляю 7-й вопрос:

7. Формат уточненного запроса

Когда ИИ генерирует финальный «уточненный запрос»:

Это просто сплошной текст (улучшенное описание)?
Или это структурированный документ (например, JSON с полями: «Цель», «Роли», «Функционал», «Стек»)?
Важно для: настройки системного промпта и того, как это отображать пользователю (просто текстовое поле или красивая таблица/список).

Итого: Если ответишь на эти 7 пунктов (можно кратко: 1-А, 2-текст, 3-блокируем и т.д.), я смогу расписать полную схему. Если на какие-то вопросы нет ответа — я предложу «Best Practice» вариант.

давай хранить в графовой БД ArangoDB
предложи классификацию вопросов от ИИ, но ИИ не должен (пока не должен) генерировать ответы, пользователь должен ввести ответы сам. Если нужно да/нет - то пользователь введет да или нет или другое утвердительную или отрицательную фразу. На этапе проверки качества ответов ИИ должен оценить, подходит такой ответ или нет.
Блокируем отправку всех ответов, пока они не будут удовлетворительными с точки зрения ИИ, и блокируем ответы, пока не исправит замечания: в пользовательском интерфейса на уровне наличия изменений (если изменил хоть одну букву, то считаем что изменения сделаны), а на уровне проверки ИИ проверяем качество ответов, и если они не устроят ИИ, то снова возвращать ответы с замечаниями (новыми), старые замечания не надо сохранять.
Да, нужна кнопка "Принять ответы без анализа ИИ", чтобы можно было продолжить. В этом случае нужно предупредить пользователя, что дальнейшая генерация может быть некорректной.
в БД ArangoDB, при этом финальный текст должен быть доступен в интерфейсе. Каждый запрос - отдельный проект, чтобы начать ввод вопроса, надо создать проект, и тогда будет доступен ввод запроса на разработку.
Пользователь может сменить модель в процессе. На каждой итерации ИИ должен получать полную информацию о проекте, при необходимости нужно использовать MCP и RAG
Уточненный запрос - текст в формате markdown, структурированный по шаблону (предложи формат шаблона сам).

Отлично, требования понятны. Внедрение ArangoDB и возможность смены моделей делает систему гибкой, а кнопка «Принудительной отправки» решает проблему потенциальных тупиков в диалоге с ИИ.

Ниже представлено подробное описание реализации 1-го этапа: «Подготовка запроса на разработку».

Техническое задание и Архитектура Системы (Этап 1)

1. Общая Архитектура

Frontend: SPA (Single Page Application) или статика (HTML/JS). Взаимодействует с n8n через REST API.
Middleware / Backend: n8n. Выполняет роль оркестратора, управляет логикой, ходит в БД и к AI провайдерам.
Database: ArangoDB. Хранит проекты, запросы, историю итераций и контекст в виде графа или документов.
AI: Подключается через HTTP Request (OpenAI API compatible) или нативные ноды n8n. Использует контекст (RAG) из данных проекта.


2. Модель Данных (ArangoDB)

Для реализации графовой структуры или документной (в зависимости от глубины связей) предлагаю следующую схему коллекций:

Projects (Document Collection):

_id
: UUID проекта.
name
: Название проекта.
created_at
: Дата.
context
: Общий контекст (описание компании, цели — база для RAG).
Requests (Document Collection):

_key
: ID запроса.
project_id
: Ссылка на проект.
status
:
draft
,
clarification
,
quality_check
,
refinement
,
completed
.
current_text
: Текущий текст запроса (исходный или отредактированный).
refined_text
: Сгенерированный Markdown.
model
: Текущая выбранная модель (напр. "gpt-4o").
Iterations (Edge Collection или вложенный массив в Requests):

Хранит историю вопросов и ответов для конкретного этапа уточнения.
Поля:
questions
(JSON),
answers
(JSON),
ai_feedback
(JSON).


3. Детальное описание процесса (Workflow)

Шаг 0: Инициализация

Пользователь создает проект. В интерфейсе выбирает модель ИИ.


Шаг 1: Первичный запрос (User -> Server)

UI: Пользователь вводит текст запроса в
textarea
. Нажимает «Отправить».
API:
POST /webhook/analyze-request
Body:
{ projectId, requestText, model }
n8n:
Сохраняет/Обновляет
Request
в ArangoDB.
RAG/Context: Собирает контекст проекта из ArangoDB.
AI Call (Ambiguity Check): Отправляет текст + системный промпт.
Logic:
Если ИИ вернул
status: "clean"
-> Переход к Шагу 4 (Генерация ТЗ).
Если ИИ вернул
status: "ambiguous"
-> Сохраняет вопросы в БД.
Response: Возвращает JSON со списком вопросов или статус успеха.

Шаг 2: Ответы на вопросы (User <-> Server Loop)

UI: Отображает список вопросов.
Поля ввода заблокированы для отправки, пока все не заполнены.
Кнопка «Отправить ответы» (Основная).
Кнопка «Принять ответы без анализа ИИ» (Force Submit) — с предупреждением.
API:
POST /webhook/submit-answers
Body:
{ requestId, answers: [{id, text}], force: boolean }
n8n:
Ветка Force (force=true): Пропускает проверку качества, сразу переходит к сохранению ответов и переходу на Шаг 4.
Ветка Normal (force=false):
AI Call (Quality Check): Отправляет пары Вопрос-Ответ на проверку.
Logic:
Если
quality: "pass"
-> Переход к Шагу 4.
Если
quality: "fail"
-> Возвращает массив замечаний (
feedback
).
UI (при наличии замечаний):
Отображает замечания красным цветом под соответствующими полями.
Блокировка: Кнопка «Отправить» (
disabled
), пока пользователь не изменит текст в полях с замечаниями (слушатель события
input
).

Шаг 3: Генерация Уточненного Запроса (Server -> AI)

n8n:
Собирает: Исходный запрос + (Вопросы + Ответы пользователя).
AI Call (Refinement): Генерирует итоговый документ в Markdown.
Сохраняет
refined_text
в ArangoDB.
Response: Возвращает Markdown клиенту.

Шаг 4: Ревизия Пользователем (User -> Server Loop)

UI: Показывает Markdown (рендеринг). Пользователь может нажать «Редактировать» и внести правки прямо в текст.
Action: Пользователь нажимает «Утвердить» или отправляет исправленный текст.
API:
POST /webhook/finalize-request
Body:
{ requestId, refinedText }
n8n:
AI Call (Re-Check): Проверяет новый текст на неопределенности (как в Шаге 1).
Если есть новые неопределенности -> Возвращает список новых вопросов (Цикл возвращается на Шаг 2).
Если чисто -> Сохраняет финальный статус
completed
.


4. Промпты и Структуры данных (JSON)

А. Классификация вопросов (System Prompt 1)

ИИ должен вернуть JSON.


Типы вопросов:

clarification
(Уточнение): Непонятен контекст или термин.
completeness
(Полнота): Не хватает важного куска функционала.
constraint
(Ограничения): Не указаны технологии, сроки или бюджет, если это критично.
logic
(Логика): Противоречие в запросе.

Output JSON Schema:


{
  "status": "ambiguous", // или "clean"
  "questions": [
    {
      "id": "q1",
      "quote": "сделать интеграцию",
      "question": "С какой именно системой нужна интеграция? Укажите название и тип API.",
      "type": "clarification"
    }
  ]

json


Б. Проверка качества ответов (System Prompt 2)

На вход подается массив:
[{question, answer}]
.
Задача ИИ: Оценить, является ли ответ информативным. Ответы "да", "нет", "не знаю" допустимы, если они закрывают вопрос по существу. Ответы "сделай сам", "потом решим" — могут быть помечены как некачественные, если блокируют разработку.


Output JSON Schema:


{
  "status": "fail", // или "pass"
  "feedback": [
    {
      "question_id": "q1",
      "comment": "Ответ 'какая-то база' слишком размыт. Уточните: SQL или NoSQL, или укажите предпочтения."
    }
  ]
}
json


В. Шаблон Уточненного Запроса (Markdown)

ИИ должен собрать всё в этот формат.


# Техническое Задание: [Название Проекта]

## 1. Обзор и Цели
Краткое описание сути проекта и бизнес-целей.

## 2. Роли Пользователей
* **[Роль 1]:** Описание прав и задач.
* **[Роль 2]:** Описание прав и задач.

## 3. Функциональные Требования

markdown



5. Реализация Frontend (Ключевые моменты)

State Management:
Храним объект
currentSession
.
При получении
feedback
от сервера, ставим флаг
hasErrors = true
.
Обработчик изменений (Dirty Check):
// Пример логики на JS
function onAnswerInput(questionId, newValue) {
    // Находим вопрос в стейте
    const q = state.questions.find(x => x.id === questionId);

    // Если было замечание от ИИ
    if (q.feedback) {
       // Проверяем, отличается ли новый текст от того, на который ругался ИИ
       if (newValue !== q.lastRejectedAnswer) {
           ui.enableSubmitButton(); // Разблокируем, если все поля исправлены

javascript

Кнопка Force Submit:
Вызывает
confirm("ИИ считает ответы неполными. Это может ухудшить ТЗ. Продолжить?")
.
При
true
отправляет флаг
force: true
.


6. Реализация n8n (Workflow)

В n8n лучше сделать один основной Workflow с роутером (Switch Node) по типу действия (
action
), либо разбить на 3 вебхука. Рекомендую подход с роутером для удобства поддержки общего контекста.


Структура Workflow:

Webhook Node: Принимает POST запросы.
ArangoDB Node (Get Context): Получает данные проекта по ID.
Switch Node (Action Type):
analyze
: -> AI Chain (Ambiguity) -> JSON Parse -> Arango Update -> Respond.
check_answers
:
If
force == true
-> Go to
refine
.
Else -> AI Chain (Quality) -> If Pass -> Go to
refine
. If Fail -> Respond with Feedback.
refine
(Sub-workflow): -> AI Chain (Generator) -> Markdown -> Arango Update -> Respond.
finalize
: -> Update Request Text -> Go to
analyze
(Loop).

Использование MCP/RAG в n8n:


В ноде AI Agent (или HTTP Request к LLM) в системный промпт динамически подставляется переменная
{{ $json.project_context }}
из ArangoDB. Это простая реализация RAG.
Если нужно искать по большой базе документов, перед вызовом LLM ставится Vector Store Tool (встроенный в n8n), который ищет релевантные куски текста и подает их в контекст модели.

Это описание полностью покрывает логику, данные и взаимодействие компонентов системы. Можно приступать к сборке в n8n.

Уточнения по процессу:

Шаг 2.

n8n. Ветка Normal: AI Call отправляет пары вопрос-ответ на проверку + системный промпт, в котором описано, что и как нужно проверять.
Должна быть доступна кнопка «Принять ответы без анализа ИИ» (Force Submit) — с предупреждением.

Шаг 3.

n8n: AI Call (Refinement) - исходный запрос + вопросы/ответы (при наличии) + системный промпт, где описано, что надо сделать и как.

Уточнения по 4. Промпты и Структуры данных (JSON):

Может быть нужно добавить в JSON Schema id проекта и id запроса? Где еще может не их хватать?
В. Шаблон Уточненного Запроса (Markdown): Заголовок не Техническое задание, а Запрос на разработку. И в БД это сущность не request, а brief, надо исправить.


Реализация n8n (Workflow). Используем подход с роутером для удобства поддержки общего контекста. Выведи исправленное описание реализации с учетом этих уточнений.


Принято. Внес все уточнения: переименовал сущность в Brief, уточнил заголовки, добавил явные упоминания системных промптов и идентификаторов в JSON-схемы для надежности связывания данных.


Ниже представлено финальное исправленное описание реализации.

Техническое задание и Реализация Системы (Этап 1: Подготовка Brief)

1. Общая Архитектура

Frontend: Веб-интерфейс (HTML/JS). Взаимодействует с n8n через REST API.
Middleware: n8n (Workflow с роутером). Оркестратор процессов.
Database: ArangoDB.
AI: Подключение по API (OpenAI-compatible).


2. Модель Данных (ArangoDB)

Переименовали
Requests
 в
Briefs
.


Projects (Collection):

_id
: UUID проекта.
name
: Название.
context
: Общий контекст проекта.
Briefs (Collection):

_key
: ID брифа (briefId).
project_id
: Ссылка на проект.
status
:
draft
,
clarification
,
refinement
,
completed
.
original_text
: Исходный текст пользователя.
current_text
: Текст после правок пользователя (если были).
refined_text
: Сгенерированный Markdown.
iterations
: Массив объектов с историей вопросов/ответов.


3. Детальное описание процесса (Workflow)

Шаг 1: Первичный запрос (User -> Server)

UI: Пользователь вводит запрос.
API:
POST /webhook/process-brief
(Action:
analyze
)
n8n:
Создает/Обновляет запись в
Briefs
.
AI Call (Ambiguity Check): Отправляет:
Текст запроса.
Системный промпт №1: Инструкция по поиску неопределенностей и формат JSON вывода.
Logic:
Если статус
clean
-> Переход к Шагу 3.
Если статус
ambiguous
-> Сохраняет вопросы.
Response: JSON с массивом вопросов +
briefId
,
projectId
.

Шаг 2: Ответы на вопросы (User <-> Server Loop)

UI:
Пользователь вводит ответы.
Доступна кнопка «Отправить ответы» (Основная).
Доступна кнопка «Принять ответы без анализа ИИ» (Force Submit) — появляется/активна всегда, но при нажатии показывает предупреждение (alert/modal): "Дальнейшая генерация может быть некорректной. Продолжить?".
API:
POST /webhook/process-brief
(Action:
check_answers
)
Body:
{ projectId, briefId, answers: [...], force: boolean }
n8n:
Ветка Force (force=true): Игнорирует проверку ИИ, сохраняет ответы, переходит к Шагу 3.
Ветка Normal (force=false):
AI Call (Quality Check): Отправляет:
Пары "Вопрос - Ответ".
Системный промпт №2: Инструкция по проверке качества (отсеивать отписки, требовать суть) и формат JSON.
Logic:
Если
pass
-> Переход к Шагу 3.
Если
fail
-> Возвращает JSON с замечаниями (
feedback
) +
briefId
.
UI (при наличии замечаний):
Показывает замечания.
Блокирует обычную отправку, пока пользователь не внесет правки.
Кнопка «Принять ответы без анализа ИИ» остается доступной для выхода из тупика.

Шаг 3: Генерация Уточненного Запроса (Server -> AI)

n8n (Action:
refine
):
Собирает контекст: Исходный запрос (или отредактированный) + История вопросов/ответов (если есть).
AI Call (Refinement): Отправляет:
Собранный контекст.
Системный промпт №3: Инструкция по генерации Markdown-документа по шаблону «Запрос на разработку».
Сохраняет результат в поле
refined_text
в ArangoDB.
Response: Возвращает JSON
{ briefId, refinedText }
.

Шаг 4: Ревизия Пользователем (User -> Server Loop)

UI: Отображает Markdown. Пользователь проверяет.
Если всё ок -> Кнопка «Утвердить».
Если нужны правки -> Пользователь редактирует текст прямо в интерфейсе -> Кнопка «Отправить на проверку».
API:
POST /webhook/process-brief
(Action:
analyze
- используем ту же логику, что в Шаге 1, но с новым текстом)
Body:
{ briefId, requestText: "Новый текст..." }
n8n:
Запускает цикл заново (Шаг 1 -> Проверка на неопределенность).
Если ИИ не находит проблем -> Финализирует бриф.


4. Промпты и Структуры данных (JSON)

Добавил
projectId
 и
briefId
 в схемы ответов сервера, так как Frontend должен знать контекст для следующих запросов. В ответе от ИИ (внутри n8n) они не обязательны, так как n8n их "знает", но сервер обязан вернуть их клиенту.


А. Классификация вопросов (System Prompt 1)

Вход: Текст запроса пользователя.
Выход (JSON от ИИ):


{
  "status": "ambiguous",
  "questions": [
    {
      "id": "q1",
      "quote": "текст из запроса",
      "question": "Текст вопроса",
      "type": "clarification"
    }
  ]

json


Ответ Сервера Клиенту:


{
  "projectId": "proj_123",
  "briefId": "brief_456",
  "status": "ambiguous",
  "questions": [...] // массив от ИИ
}
json


Б. Проверка качества ответов (System Prompt 2)

Вход: JSON массив
[{question, answer}]
.
Выход (JSON от ИИ):


{
  "status": "fail",
  "feedback": [
    {
      "question_id": "q1",
      "comment": "Ответ не содержит конкретики."
    }
  ]
}
json


Ответ Сервера Клиенту (при ошибке):


{
  "projectId": "proj_123",
  "briefId": "brief_456",
  "status": "quality_check_failed",
  "feedback": [...] // массив от ИИ
}
json


В. Генерация (System Prompt 3)

Вход: Исходный текст + JSON с вопросами/ответами.
Задача: Сформировать документ Markdown.
Шаблон:


# Запрос на разработку: [Название Проекта]

## 1. Обзор и Цели
...
## 2. Роли Пользователей
...
## 3. Функциональные Требования
...
## 4. Нефункциональные Требования
...

markdown



5. Реализация n8n (Workflow с Роутером)

Используем один Webhook с параметром
action
 в теле запроса.


Nodes Flow:


Webhook (POST): Принимает
{ action, projectId, briefId, ...data }
.

ArangoDB (Get Brief): Получает текущее состояние брифа и контекст проекта по
briefId
.

Switch Node (Router): Маршрутизация по полю
action
.

Route 1:
analyze
(Шаг 1 и 4)

-> AI Agent (Ambiguity Check): Использует System Prompt 1.
-> If Ambiguous:
-> ArangoDB (Save Questions).
-> Respond (JSON with Questions).
-> If Clean:
-> Go to Route 3 (
refine
).
Route 2:
check_answers
(Шаг 2)

-> If
force === true
:
-> ArangoDB (Save Answers).
-> Go to Route 3 (
refine
).
-> If
force === false
:
-> AI Agent (Quality Check): Использует System Prompt 2.
-> If Pass:
-> ArangoDB (Save Answers).
-> Go to Route 3 (
refine
).
-> If Fail:
-> Respond (JSON with Feedback).
Route 3:
refine
(Шаг 3)

-> AI Agent (Generator): Использует System Prompt 3. На вход подает
original_text
+
iterations
.
-> ArangoDB (Update
refined_text
, set status
refinement
).
-> Respond (JSON with Markdown).
Route 4:
finalize
(Финал)

-> ArangoDB (Set status
completed
).
-> Respond (Success).

Это описание полностью соответствует твоим уточнениям и готово к реализации.

Нужно добавить возможность не только выбора модели ИИ на старте и смены модели в процессе, но и выбор системных промптов.
В настройках проекта и перед отправкой ИИ нужно показывать в пользовательском интерфейсе системный и пользовательский промпт, и дать возможность пользователю выбрать другой системный промпт из репозитория, т.е. нужен еще репозиторий системных промптов, отображение в пользовательском интерфейсе таймлайна подготовки требований, где будет указан текущий этап, пройденные этапы, будущие этапы, и настройки по каждому этапу: указана модель ИИ с возможностью выбора, указана версия системного промпта (заголовок), с возможностью выбора другого системного промпта из репозитория, и заголовок пользовательского промпта с возможностью выбора другого из репозитория или редактирования пользовательского промпта прямо в пользовательском интерфейсе перед отправкой. Нужен так же интерфейс управления пользовательскими и системными промптами, интерфейс управления моделями ИИ, если он нужен, а может быть и не нужен, и настраивать подключение к моделям ИИ можно в n8n? Так же нужно добавить счетчик итераций уточнений.
















Это существенное расширение функционала, которое превращает систему в полноценный LLM Ops инструмент для бизнес-анализа.


Ниже описаны изменения в архитектуре, базе данных и интерфейсе для поддержки репозитория промптов, таймлайна и управления конфигурациями.



Обновленная Архитектура (v2)

1. Изменения в Модели Данных (ArangoDB)

Добавляем коллекции для управления конфигурациями.


Prompts (Document Collection) — Репозиторий промптов.

_key
: ID промпта.
title
: Название (напр. "Строгий поиск неопределенностей").
type
:
system
или
user_template
.
stage
: Для какого этапа (
ambiguity
,
quality
,
refinement
).
content
: Текст промпта (с плейсхолдерами, например
{{text}}
).
version
: Версия.
AI_Models (Document Collection) — Справочник доступных моделей.

_key
: ID (напр.
gpt-4o
,
claude-3-5
).
name
: Отображаемое имя ("GPT-4 Omni").
provider
:
openai
,
anthropic
,
ollama
.
context_window
: Размер окна (для инфо).
Briefs (Обновление) — Хранение истории настроек.

iteration_count
: Счетчик итераций (Integer).
history
: Массив, где каждый элемент хранит не только вопросы/ответы, но и
used_model
,
used_system_prompt
,
used_user_prompt
для аудита.


2. Пользовательский Интерфейс (UI)

А. Таймлайн (Timeline)

В верхней части экрана отображается прогресс-бар с этапами:

Запрос (Текущий)
Уточнение (Будущий)
Ревизия (Будущий)
Финал (Будущий)

Активный этап подсвечивается.
Рядом с текущим этапом отображается Счетчик итераций: «Итерация 2».

Б. Панель настройки этапа (Stage Config)

Перед кнопкой «Отправить» (на любом этапе) располагается сворачиваемая панель «Настройки генерации»:

Выбор Модели ИИ:
Dropdown со списком из коллекции
AI_Models
.
Логика: n8n будет использовать этот ID для выбора модели.
Системный Промпт:
Dropdown: Выбор из репозитория
Prompts
(фильтр по текущему этапу).
Preview: При выборе показывает текст промпта (read-only или editable — по желанию, лучше read-only с кнопкой «Клонировать/Создать новый»).
Пользовательский Промпт:
Dropdown: Выбор шаблона (напр. «Стандартный», «С фокусом на безопасность»).
Textarea (Редактируемый): Сюда подставляется шаблон + данные пользователя (текст запроса или ответы).
Важно: Пользователь может вручную дописать сюда инструкции перед отправкой (например: "Проверь строже раздел про API").

В. Интерфейс управления (Admin Panel)

Отдельная страница или модальное окно:

Менеджер Промптов: Таблица с CRUD (Создать, Читать, Обновить, Удалить). Поля: Название, Текст, Этап.
Менеджер Моделей: Добавление идентификаторов моделей, которые поддерживаются в n8n.
Примечание: Сами API ключи настраиваются в Credentials n8n, а здесь мы просто ведем список доступных для выбора в UI названий.


3. Обновленный Процесс (Workflow)

Теперь Frontend не просто отправляет данные, а отправляет полную конфигурацию запроса.


Пример: Шаг 1 (Первичный запрос)

UI (Init): При загрузке страницы запрашивает
GET /webhook/config
-> получает списки моделей и промптов.
UI (Render): Пользователь вводит запрос. В настройках выбирает модель
GPT-4
и системный промпт
Ambiguity Check v2
.
UI (Prepare):
Берет шаблон пользовательского промпта.
Подставляет в него текст запроса.
Показывает пользователю в поле "Пользовательский промпт".
Пользователь может дописать: "Не задавай вопросы про дизайн".
API Request:
POST /webhook/process-brief
{
  "action": "analyze",
  "projectId": "...",
  "config": {
    "modelId": "gpt-4o",
    "systemPrompt": "Текст системного промпта...",
    "userPrompt": "Текст пользовательского промпта (с данными)..."
  },
  "data": { ... } // сырые данные для сохранения в БД (чтобы отделить промпт от данных)

json

n8n:
Получает
systemPrompt
и
userPrompt
прямо из запроса. Больше не хранит промпты внутри нод.
Сохраняет использованные промпты в историю итерации в ArangoDB.
Передает
modelId
в ноду AI Agent (используя Expression для выбора модели).
Выполняет генерацию.
Инкрементирует счетчик итераций в БД.


4. Реализация в n8n (Dynamic Configuration)

Чтобы это работало, Workflow в n8n должен стать полностью динамическим.


1. Подключение Моделей:
Вместо жестко заданной модели в ноде "OpenAI Chat Model", используем Expression для поля
Model Name
.


Expression:
{{ $json.body.config.modelId }}
.
Нюанс: Если вы используете разных провайдеров (OpenAI vs Anthropic), перед вызовом AI нужно поставить Switch Node, который по префиксу модели (или полю
provider
из БД) направит запрос в соответствующую ноду (OpenAI Node или Anthropic Node).

2. Промпты:


В ноде AI Agent (или HTTP Request):

System Message =
{{ $json.body.config.systemPrompt }}
User Message =
{{ $json.body.config.userPrompt }}

3. Вспомогательный Workflow (Config API):
Создать отдельный Workflow на вебхук
GET /webhook/config
.


Запрос в ArangoDB:
FOR p IN Prompts RETURN p
,
FOR m IN AI_Models RETURN m
.
Ответ: JSON с массивами промптов и моделей для инициализации UI.


Итоговая схема взаимодействия (Этап 1 с настройками)

Старт: UI загружает списки промптов и моделей из n8n.
Настройка: Пользователь пишет запрос, выбирает модель, выбирает пресет системного промпта. Видит сформированный запрос к ИИ, может его поправить.
Отправка: UI шлет всё (тексты промптов + ID модели) в n8n.
Исполнение: n8n исполняет запрос с полученными параметрами.
История: n8n сохраняет результат и метаданные (какой промпт/модель использовались) в ArangoDB.
Таймлайн: UI обновляет счетчик итераций и статус этапа.

Это дает максимальную гибкость: вы можете менять логику работы ИИ (промпты) прямо из админки, не трогая Workflow в n8n, а пользователь может адаптировать запросы "на лету".

пользовательский интерфейс будет напрямую взаимодействовать с ArangoDB, или лучше сделать это через n8n, чтобы из пользовательского интерфейса не было доступа в базу данных напрямую?












Однозначно лучше делать через n8n.


Прямой доступ из браузера (Frontend) в базу данных (ArangoDB) — это критическая уязвимость безопасности.


Почему только через n8n (Middleware):

Безопасность (Security):

Если фронтенд ходит в базу напрямую, вам придется хранить учетные данные (логин/пароль или токен) внутри JavaScript кода в браузере. Любой пользователь может открыть "Исходный код" страницы, украсть ключи и получить полный доступ к вашей базе (удалить всё или скачать данные конкурентов).
n8n хранит креды внутри себя (на сервере), фронтенд знает только публичный адрес вебхука.
Валидация данных:

n8n выступает как бэкенд. Перед тем как записать данные в ArangoDB, n8n может проверить, заполнил ли пользователь обязательные поля, не пытается ли он подменить ID чужого проекта и т.д.
Инкапсуляция логики:

Если вы захотите изменить структуру БД или вообще сменить ArangoDB на Postgres, вам придется переписывать весь фронтенд. Если использовать n8n как прослойку, вы поменяете только ноды в n8n, а фронтенд даже не узнает об изменениях.

Как это реализовать в n8n (API Gateway)

Чтобы не плодить сотню вебхуков для каждого чиха (получить список промптов, получить проект, сохранить настройки), рекомендую сделать 2 основных Workflow:

1. Workflow "Data API" (CRUD операции)

Обслуживает запросы интерфейса на чтение/запись вспомогательных данных.


Webhook:
POST /webhook/api
Body:
{ entity: "prompts", action: "list" }
или
{ entity: "project", action: "get", id: "..." }
Switch Node: Маршрутизирует по
entity
и
action
.
Ветка
prompts/list
: Запрос в Arango
FOR p IN Prompts RETURN p
-> Ответ JSON.
Ветка
models/list
: Запрос в Arango
FOR m IN AI_Models RETURN m
-> Ответ JSON.
Ветка
project/create
: Создает проект -> Возвращает ID.

2. Workflow "Process Engine" (Бизнес-логика)

Тот самый сложный воркфлоу, который мы обсуждали ранее (анализ, генерация, проверка).


Webhook:
POST /webhook/process-brief
Занимается только тяжелыми задачами с ИИ.

Итог: Фронтенд общается только с вебхуками n8n. База данных ArangoDB закрыта от внешнего мира фаерволом и принимает подключения только от сервера n8n.

Эта схема генерации и уточнения может подойти для генерации требований по запросу на разработку? Какие изменения надо внести в описание проекта?














Да, эта схема (Анализ -> Уточнение -> Генерация -> Ревизия) является универсальным паттерном для работы с LLM и идеально подходит для генерации детальных требований (SRS, User Stories, Use Cases).


По сути, «Запрос на разработку» (Бриф) — это высокоуровневые требования. А «Техническое задание» — это детальные требования. Разница только в уровне абстракции и входных данных.


Чтобы трансформировать описанную систему из «Генератора Брифов» в «Систему генерации полного пакета требований», нужно внести следующие изменения в описание проекта:

1. Изменение Модели Данных (Обобщение)

Вместо жесткой сущности
Briefs
, нам нужна сущность
Documents
 (или
Artifacts
), так как требований будет много разных типов.


Было: Коллекция
Briefs
.
Стало: Коллекция
Documents
.
Добавляем поле
type
:
brief
(Запрос на разработку — то, что мы уже сделали).
functional_req
(Функциональные требования).
user_stories
(Пользовательские истории).
database_schema
(Схема БД).
Добавляем поле
parent_id
: Ссылка на родительский документ. Например,
functional_req
создаются на основе утвержденного
brief
.

2. Изменение Логики Контекста (RAG)

Для генерации детальных требований (Этап 2) контекстом является не просто «идея из головы», а утвержденный результат Этапа 1.


Изменение в описании:
На вход ИИ (в промпт) теперь подается не только текущий ввод пользователя, но и весь текст родительских документов.
Пример: При генерации «Функциональных требований» система должна подгрузить текст утвержденного «Брифа» из Этапа 1.

3. Изменение в Таймлайне и Этапах

Процесс теперь не линейный (один раз прошли и всё), а многоступенчатый.


Изменение в UI:
Таймлайн теперь показывает не шаги внутри одного документа, а список документов, которые нужно создать:
Бриф (Готово)
Архитектура (В процессе)
API Спецификация (Ожидание)
Внутри каждого документа работает тот самый цикл (Анализ -> Вопросы -> Генерация), который мы описали.

4. Декомпозиция (Самое важное изменение)

Детальные требования нельзя сгенерировать одним куском текста (упремся в лимиты контекста ИИ).


Новая функция: Возможность генерации требований помодульно.
Изменение в процессе:
Пользователь (или ИИ) сначала генерирует Структуру документа (список заголовков/модулей).
Затем запускает процесс генерации (наш цикл уточнения) для каждого модуля отдельно.

Резюме: Что поправить в ТЗ

Если ты хочешь использовать это описание как базу для полной системы, внеси эти правки в текст:

Замени слово
Brief
на
Document
во всех схемах БД и API.
Добавь понятие
Document Type
в настройки конфигурации (чтобы подтягивать нужные промпты: для брифа одни, для SQL-схемы другие).
Добавь в описание n8n шаг «Сбор контекста» (Context Assembly): Перед отправкой в ИИ, скрипт должен найти все утвержденные документы этого проекта и склеить их в один контекстный файл для ИИ.

Вердикт: Архитектура (n8n + ArangoDB + Циклы уточнений) менять не нужно. Она отличная. Нужно только масштабировать модель данных, чтобы она поддерживала цепочку документов, а не один файл.

то, какой артефакт будет на выходе итеративной генерации, зависит от входных данных и системных промптов.
Если на входе уточненный запрос на разработку, а системный промт ставит задачу генерации бизнес-требований, то на выходе будет документ бизнес-требований.
При этом описываемый процесс итеративного уточнения - это универсальный инструмент, который можно использовать в разных workflow, и такая итеративная генерация поможет исключить ограничения в размере контекстного окна, если каждое обращение к ИИ - это новый чат. Но чтобы модель максимально была в контексте проекта в целом, что нужно использовать - RAG, MCP или оба сразу? Как лучше хранить данные проекта (сгенерированные требования) - в БД или в репозитории git?










Ты абсолютно прав. Описываемый процесс — это универсальный «Движок уточнения и генерации» (Refinement Engine). Меняя входные данные (контекст) и системные промпты (задачу), мы можем генерировать что угодно: от бизнес-требований до тест-кейсов и SQL-схем.


Вот ответы на твои архитектурные вопросы:

1. Как держать ИИ в контексте (RAG vs MCP vs Context Window)

Для генерации качественных требований критически важно, чтобы ИИ видел целостную картину, а не вырванные куски.


Рекомендация: Иерархическая инъекция контекста (Smart Context Injection)


Учитывая, что современные модели (GPT-4o, Claude 3.5 Sonnet) имеют контекстное окно 128k–200k токенов (это сотни страниц текста), для большинства проектов RAG в классическом виде (поиск по векторам) будет вреден. Векторный поиск может «потерять» важную деталь, которая связывает два модуля, и требования выйдут противоречивыми.


Лучшая стратегия:

Основной метод (Context Injection): При генерации Артефакта №2 (Бизнес-требования), мы целиком помещаем Артефакт №1 (Уточненный запрос) в системный промпт.
Почему: Требования должны строго соответствовать запросу. ИИ должен видеть каждое слово исходника.
RAG (Вспомогательный): Используем только для внешних знаний, которые не меняются в рамках проекта.
Пример: Корпоративные стандарты оформления, ГОСТы, документация по API сторонней системы, с которой интегрируемся. Эти данные не влезут в контекст, их надо искать вектором.
MCP (Model Context Protocol): Это идеальный вариант для сложных графовых запросов в будущем.
Как использовать: Поскольку у нас ArangoDB (граф), мы можем дать ИИ инструмент (Tool)
get_related_documents(id)
. Если ИИ пишет требования для модуля «Оплата», он сам может «подтянуть» через MCP связанные требования из модуля «Корзина», если почувствует, что ему не хватает контекста.
Для старта: Достаточно п.1. MCP внедрять, когда связей станет слишком много.

2. Где хранить данные: ArangoDB или Git?

Это классическая дилемма: «Структура против Версионирования».


Ответ: ArangoDB — как «Source of Truth» для системы, Git — как результат (экспорт).


Почему ArangoDB должна быть главной:

Графовые связи: Требования — это не просто текст. Это граф.
Требование БТ-01 связано с Функцией ФТ-05, которая связана с Тест-кейсом ТК-10.
В Git (Markdown файлах) эти связи поддерживать вручную невозможно. В ArangoDB это нативные ребра графа (
Edges
).
Метаданные и Статусы: У каждого требования есть статус (
draft
,
review
,
approved
), приоритет, автор. В Git это придется писать в YAML-шапку файла, что неудобно парсить для UI.
Гранулярность: В БД мы можем хранить каждое требование отдельным объектом (документом). Это позволяет ИИ переписывать только одно требование, не перелопачивая весь файл целиком.

Роль Git:
Git идеален для разработчиков и финальной фиксации.


Реализация: Сделай в n8n workflow «Экспорт в Git».
Когда этап завершен (статус
completed
), n8n берет данные из ArangoDB, собирает из них красивый Markdown-файл (или структуру папок) и делает коммит в репозиторий проекта (GitLab/GitHub).

Итоговая архитектура контекста

Хранилище (ArangoDB): Хранит граф артефактов.
Brief
(Node) ->
BusinessReqs
(Node) ->
TechReqs
(Node).
Сборщик контекста (n8n):
Перед вызовом ИИ скрипт идет в граф.
Собирает текст всех родительских узлов (вверх по графу).
Собирает текст соседних узлов (если нужно).
Склеивает это в один большой текст:
PROJECT_CONTEXT
.
Генератор (AI):
Получает
PROJECT_CONTEXT
.
Получает
SYSTEM_PROMPT
(например: "Ты системный аналитик, напиши функциональные требования...").
Генерирует новый артефакт.
Сохранение: Новый артефакт пишется в ArangoDB как новый узел, связанный с предыдущими.

Такой подход исключает "галлюцинации" из-за потери контекста и позволяет строить сложные цепочки документов.

ты пишешь:

"Графовые связи: Требования — это не просто текст. Это граф.
Требование БТ-01 связано с Функцией ФТ-05, которая связана с Тест-кейсом ТК-10."
Как тогда правильно хранить требования в ArangoDB, чтобы можно было делать такую трассировку? Можно ли хранить текст отдельно, а разбиение на отдельные требования отдельно, чтобы не вносить в текст требований лишнюю разметку, а если требования в формате markdown, то можно деление на требования хранить в отдельной коллекции, где каждый объект коллекции будет содержать, например
{
"fragments": [
{
"uid": "uuid-v4",
"id": "BR-0001",
"type": "Business Requirement",
"text": "Полный текст фрагмента",
"source_file": "docs/requirements.md", //или uid документа в коллекции, где хранится полный текст документов
"location": {
"start": {"line": 5, "column": 0},
"end": {"line": 15, "column": 42}
},
"metadata": {
"created_at": "2024-01-15T10:30:00Z",
"created_by": "
user@example.com
",
"updated_at": "2024-01-16T14:20:00Z",
"updated_by": "
user@example.com
",
"version": 2,
"status": "active",
"priority": "high",
"tags": ["важный", "первая_итерация"]
},
"hash": "sha256-хеш_текста",
"embeddings_ref": "embeddings/br-0001.json"
}
]
}
плюс еще можно добавить качество требований (например, содержит или не содержит неопределенность), или качество требований определять связями например с классификатором качественных показателей требований.
Связи могут быть типизированными, и определять зависимость, иерархию, последовательность, дублирование, противоречие и что еще нужно для трассировки требований
{
"edges": [
{
"from_uid": "uuid-source",
"to_uid": "uuid-target",
"relationship_types": ["depends_on", "refines"],
"metadata": {
"created_at": "2024-01-15T11:00:00Z",
"created_by": "
user@example.com
",
"confidence": 0.95,
"source": "manual|drawio|llm_generated",
"description": "Требование BR-0001 зависит от FR-0003"
}
}
]
}
И еще скажи, какое у тебя контекстное окно, не пора ли в новый чат переходить?












Твой подход к модели данных очень профессиональный. Ты фактически описываешь архитектуру промышленной RMS (Requirements Management System), такой как IBM DOORS или Jama Software, но на современном стеке.


Однако, в твоем предложении есть одна критическая уязвимость: привязка к номерам строк (
location: {start: line 5}
).


Проблема синхронизации (Location Hell)

Если мы храним полный текст в одном месте, а метаданные фрагментов — в другом, привязываясь к строкам:

Пользователь открывает Markdown и вставляет один абзац в начале.
Все строки смещаются на +5.
Все записи в коллекции
fragments
теперь указывают не туда. Данные рассинхронизированы.

Как сделать правильно (Atomic Design)

Чтобы реализовать трассировку и графовые связи, нужно сделать «Атомарные требования» источником правды (Source of Truth).


Рекомендуемая схема ArangoDB:


Коллекция
Documents
(Nodes):

Хранит только «контейнер»: Название документа, Версия, Статус.
Не хранит полный текст.
Коллекция
Requirements
(Nodes) — твои "Fragments":

Здесь лежит контент.
_key
: UUID.
human_id
: "BR-001" (читаемый ID).
text
: "Система должна..." (Markdown текст конкретного требования).
metadata
: { priority, status, author... }.
quality_check
: { has_ambiguity: false, score: 0.9 }.
Коллекция
Structure
(Edges):

Связывает
Document
->
Requirement
.
В ребре храним порядок (
position: 10
,
position: 20
).
Как собрать документ: Делаем графовый запрос: "Найти все ноды, связанные с Документом Х, отсортировать по
position
". n8n склеивает их тексты и отдает на фронт как единый Markdown.
Коллекция
Traceability
(Edges) — то, что ты описал:

Связывает
Requirement
->
Requirement
(или
Test
,
Function
).
type
:
depends_on
,
conflicts_with
,
verifies
.
Это позволяет строить Matrix Traceability.

Преимущества такого подхода:


Редактирование: Когда пользователь правит текст в UI, он правит конкретный объект
Requirement
. Остальные не ломаются.
Версионирование: Изменилось одно требование — мы обновили версию только у него (и у документа-контейнера), а не пересохраняем мегабайт текста.
ИИ: ИИ может анализировать связи: "Требование А изменилось, найди по ребрам
depends_on
, какие требования Б и В надо перепроверить".


Ответ про контекстное окно

У меня (как у модели) контекстное окно достаточно большое (до 128k токенов), и мы пока использовали лишь малую часть. Мы можем продолжать здесь.


Однако, мы сейчас переходим от «Процесса генерации» (Workflow) к «Проектированию Базы Данных» (Data Modeling). Это фундаментально другая тема.


Если ты хочешь зафиксировать результаты по Workflow (Этап 1) и начать углубленно прорабатывать структуру БД (с JSON схемами, AQL запросами и т.д.) — лучше начать новый чат. Это поможет тебе структурировать информацию: один чат — ТЗ на процесс, второй чат — ТЗ на архитектуру БД.


Рекомендую:


Скопируй итоговое описание процесса из этого чата.
Начни новый чат с промптом: "Проектируем структуру БД ArangoDB для системы управления требованиями. Вводные данные: требования храним атомарно, нужны графовые связи..." и вставь свои JSON примеры — они отличные.
прежде, чем перейдем в другой чат, ответь на вопрос: как в UI можно редактировать требования? Будет ли это редактирование одного документа, и как в этом случае можно отслеживать, какое атомарное требование редактирует пользователь, чтобы это не выглядело, как куча отдельных полей ввода?
В случае, если мы храним полный текст в одном месте, а метаданные фрагментов — в другом, привязываясь к строкам, когда пользователь вносит изменения, можно вероятно автоматически менять привязку неизмененных фрагментов, и если пользователь вставил абзац в начале, то это можно отследить, и пересчитать номера строк во всех фрагментах документа. Или это очень ресурсоемко и может привести к серьезным сбоям? Хотя эти сбои будут в рамках только одного документа, а хранение точных цитат поможет восстановить привязку автоматически.









Это отличный вопрос, который касается самого сердца UX (пользовательского опыта).


Вариант 1: Редактирование «Монолитного текста» с пересчетом (Сложный путь)

Ты прав, технически это возможно. Алгоритм выглядит так:

Храним
original_text
(цитату) для каждого требования.
Пользователь редактирует весь документ как единый текст.
При сохранении сервер запускает алгоритм Diff (сравнения):
Ищет неизмененные куски текста -> обновляет их координаты (строки).
Ищет похожие куски (Fuzzy Matching) -> если текст изменился незначительно (исправили опечатку), обновляет текст требования, сохраняя ID.
Если кусок текста исчез -> помечает требование как
deleted
.
Если появился новый кусок -> создает новое требование.

Риски:


Проблема Тесея: Если пользователь переписал требование на 80%, алгоритм может решить, что старое требование удалено, а новое создано. Результат: Потерялись связи с тест-кейсами и история изменений. ID изменился с
BR-001
на
BR-055
.
Слияние/Разделение: Пользователь нажал Enter посередине требования. Это теперь два требования? Какому из них достанется ID
BR-001
? Алгоритм не может решить это за человека.

Вариант 2: Блочный редактор (Notion-style) — Рекомендуемый

Современный стандарт интерфейсов (Notion, Coda, WordPress Gutenberg) решает именно эту проблему.


Как это выглядит для пользователя:
Пользователь видит единый документ. Нет никаких рамок, полей ввода или кнопок "Сохранить" у каждой строки. Он просто кликает и пишет.


Как это работает под капотом:
Фронтенд использует библиотеку Block Editor (например, Editor.js, TipTap, ProseMirror).


Каждый абзац (параграф) в редакторе — это отдельный программный объект (Блок).
У каждого Блока есть скрытый
data-id="uuid-v4"
.
Когда пользователь нажимает
Enter
, редактор создает новый Блок с новым ID.
Когда пользователь нажимает
Backspace
и склеивает строки, редактор удаляет Блок.

Взаимодействие с БД:

Пользователь редактирует "документ".
Фронтенд отправляет на сервер не "текст", а JSON-структуру блоков:
[
  { "id": "uuid-1", "type": "header", "data": { "text": "Бизнес-требования" } },
  { "id": "uuid-2", "type": "paragraph", "data": { "text": "Система должна..." } }
]
json

n8n (или бэкенд) пробегается по этому массиву:
Блок с
uuid-2
уже есть в БД? -> Обновляем текст
BR-001
.
Блок новый? -> Создаем
BR-002
.
Блок исчез из списка? -> Помечаем
BR-xxx
как удаленный.

Почему это лучше:

100% Точность: Мы никогда не потеряем привязку ID, потому что ID "живет" в DOM-элементе редактора.
UX: Выглядит как обычный Word/Google Doc.
Производительность: Не нужно гонять сложные Diff-алгоритмы на сервере.

Вывод:
Не иди по пути парсинга строк и цитат — это "минное поле" багов. Используй на фронтенде TipTap или Editor.js. Они созданы ровно для того, чтобы редактировать структурированный контент так, будто это простой текст. В ArangoDB тогда каждый такой "блок" будет ложиться в документ коллекции
Requirements
 идеально.

ты описываешь проблему:

"Слияние/Разделение: Пользователь нажал Enter посередине требования. Это теперь два требования? Какому из них достанется ID


BR-001

? Алгоритм не может решить это за человека."


но дальше описывая преимущества блочного редактора, пишешь:

"Когда пользователь нажимает
Enter
, редактор создает новый Блок с новым ID.
Когда пользователь нажимает
Backspace
и склеивает строки, редактор удаляет Блок."
Кто решит в случае с блочным редактором, Какому из них достанется ID


BR-001?












Ты зришь в корень. Давай разберем этот механизм, потому что разница между «Алгоритм гадает на сервере» и «Редактор исполняет правило на клиенте» принципиальная.


В случае с блочным редактором (TipTap/ProseMirror) решение принимает программная логика редактора в момент нажатия клавиши, и это решение всегда детерминировано (предсказуемо).


Вот стандартные правила поведения таких редакторов, которые де-факто стали стандартом:

1. Сценарий: Разделение (Enter)

У нас есть блок:
ID: BR-001
. Текст: "Система должна авторизовать и печатать чек".
Курсор стоит после слова "авторизовать". Пользователь жмет Enter.


Правило редактора: Исходный блок (
BR-001
) остается на месте, но его текст обрезается до курсора. Создается новый блок (
BR-new
) с текстом после курсора.
Результат:
BR-001
: "Система должна авторизовать" (ID сохранился за верхней частью).
BR-new
: "и печатать чек" (Новый ID).
Почему это хорошо: Связи (Traceability), которые вели к
BR-001
(например, Тест-кейс на авторизацию), останутся привязанными к первой части. Вторая часть станет "новым требованием без покрытия", что логично — аналитик должен создать для него новые связи.

2. Сценарий: Слияние (Backspace/Delete)

У нас два блока.

BR-001
: "Авторизация"
BR-002
: "Печать чека" Курсор в начале второго блока. Пользователь жмет Backspace.

Правило редактора: Контент второго блока переносится в конец первого. Второй блок удаляется из DOM.
Результат:
BR-001
: "Авторизация Печать чека" (Впитал в себя текст).
BR-002
: Удален.
Почему это хорошо: Мы точно знаем, что
BR-002
перестал существовать. Система может выдать предупреждение: "Внимание, вы удаляете требование BR-002, которое имеет 5 связей. Перенести связи на BR-001?". При Diff-алгоритме мы бы узнали об этом только постфактум, когда спасать связи было бы поздно.

Резюме

В блочном редакторе нет неопределенности.


Enter =
Старый ID
остается сверху, снизу рождается
Новый ID
.
Backspace =
Верхний ID
поглощает текст,
Нижний ID
умирает.

Это жесткие правила. Да, иногда они могут не совпасть с мыслью пользователя (он хотел, чтобы ID ушел вниз), но пользователь быстро привыкает к этой механике, так как она работает везде (в Word, Google Docs, Notion). Главное — система всегда знает, что произошло, и база данных остается целостной.

А если нужно в одном требовании несколько строк?









{
  "id": "req-001",
  "type": "requirement_item",
  "content": [
     { "type": "paragraph", "text": "Line 1" },
     { "type": "list", "items": [...] }
  ]
}





Это решается двумя способами, в зависимости от того, насколько сложную структуру требования вы хотите поддерживать.


Способ 1. Мягкий перенос (Soft Break) — Простой вариант

Это стандартное поведение всех редакторов (Word, Notion, Slack, Telegram).


Enter = Новый блок (Новое требование).
Shift + Enter = Перенос строки внутри того же блока.

В этом случае внутри блока сохраняется символ переноса строки (
\n
 или тег
<br>
), но ID остается прежним. Этого достаточно для 90% случаев, когда нужно просто разбить текст на абзацы.


Способ 2. Требование-Контейнер (Nested Blocks) — Продвинутый вариант

Если требование — это не просто текст, а, например, "Текст + Маркированный список + Таблица", то одного текстового блока мало.


В этом случае мы настраиваем редактор (например, TipTap) так, что Требование — это не параграф, а «Обертка» (Wrapper/Card).


Как это работает:

В редакторе визуально Требование выглядит как блок с легкой рамкой или цветной полоской сбоку (где написан ID
BR-001
).
Внутри этой рамки может находиться сколько угодно обычных параграфов, списков или картинок.
Все они вложены в родительский объект
Requirement
.

Поведение клавиш:


Enter (внутри рамки): Создает новый параграф внутри того же требования
BR-001
.
Ctrl + Enter (или тройной Enter): Выходит из рамки и создает новое требование
BR-002
.

Структура данных (JSON):


{
  "id": "req-uuid-001",
  "type": "requirement", // Тип-контейнер
  "data": {
    "status": "draft",
    "human_id": "BR-001"
  },
  "content": [ // Вложенные блоки
    { "type": "paragraph", "text": "Система должна..." },
    { "type": "bulletList", "content": [...] },

json


Рекомендация:
Для MVP (минимальной версии) достаточно Способа 1 (Shift+Enter). Это привычно пользователям и легко реализуется.
Если вы делаете профессиональный инструмент, где требование может занимать полстраницы со схемами — планируйте Способ 2.

в Confluence используется такой редактор?








Да, именно так.


Современный Confluence Cloud использует редактор, построенный на технологии ProseMirror. Это та самая технология «блочного редактирования» (на базе которой сделан и TipTap, который я рекомендовал выше).


Как это устроено в Confluence:

JSON вместо HTML: Confluence не хранит страницу как HTML-код. Он хранит её в формате ADF (Atlassian Document Format) — это JSON-дерево блоков.
Вложенность: Если ты вставляешь в Confluence «Макрос» (например, Info Panel или Expand), ты создаешь Блок-контейнер. Внутри него ты можешь писать текст, вставлять списки и картинки. Это ровно тот Способ 2, который я описал.
Enter vs Shift+Enter: В Confluence это работает стандартно. Enter — новый параграф (новый блок), Shift+Enter — перенос строки.

Разница с твоей задачей:
Confluence — это вики общего назначения. Он не присваивает каждому параграфу уникальный ID типа
BR-001
 автоматически (хотя технически у каждого узла в ProseMirror может быть ID).


Ты же строишь специализированную систему. Твоя задача — взять тот же движок (ProseMirror/TipTap), но добавить правило: «Каждый блок верхнего уровня (или специальный блок "Requirement") обязан иметь видимый ID и сохраняться в БД как отдельная сущность».


Так что да, выбирая эту архитектуру, ты идешь по пути технологических лидеров (Atlassian, Notion).

Нужно переходить к следующим этапам, для этого надо вывести полный текст



Нужно переходить к следующим этапам, для этого надо вывести полный текст описания проекта, который послужит контекстом для дальнейшей разработки.
Но прежде, чем его выводить, проанализируй беседу, найди неопределенности в выборе технического решения и в требованиях, задай вопросы, и после уточнения можно будет вывести текст описания проекта. В конце описания проекта нужно вывести роадмап реализации этого проекта.














Я проанализировал нашу беседу. Мы проделали огромный путь от простой схемы "Запрос-Ответ" до архитектуры профессиональной системы управления требованиями (RMS).


Однако, перед финальной сборкой описания, есть 3 критические неопределенности, которые сильно влияют на стек технологий и сложность реализации (особенно Роадмапа).


Вопросы для уточнения:

1. Технологический стек Frontend (из-за Блочного Редактора)
В начале мы говорили про «статический сайт HTML+JS». Но позже мы утвердили использование Блочного редактора (типа Notion/Confluence) на базе ProseMirror или TipTap.


Реализовывать такой редактор на чистом JS (Vanilla) — это огромная боль и риск. Библиотеки типа TipTap/Editor.js заточены под реактивные фреймворки.
Вопрос: Можем ли мы зафиксировать в стеке использование Vue.js или React? (Это упростит разработку редактора в разы). Или есть жесткое ограничение на чистый JS?

2. Авторизация и Многопользовательский режим
В схеме БД мы упоминали
created_by: user@example.com
, но не обсуждали систему входа.


Вопрос:
А) Это SaaS/Многопользовательская система: Нужна регистрация, логин, права доступа (User A не видит проекты User B).
Б) Это Внутренний инструмент (Single Tenant): Один инстанс на команду, без сложной авторизации (или базовая Basic Auth на входе в n8n/nginx).

3. Сложность структуры Требования (MVP vs Target)
Мы обсудили два варианта редактора: простой (Enter = новое требование) и сложный (Требование-Контейнер с вложениями).


Вопрос: Для первой версии (MVP) мы делаем:
А) Простой список: Одно требование = Один текстовый блок. (Быстро, дешево).
Б) Полноценные контейнеры: Требование может содержать картинки, таблицы и списки внутри себя. (Сложнее в разработке UI, но нужно для серьезных ТЗ).

4. Интеграция с Git


Вопрос: Реализуем только Экспорт (нажал кнопку -> улетело в GitLab) или планируем Двустороннюю синхронизацию (разработчик поправил README.md в Git -> обновилось в ArangoDB)? Рекомендую для старта только Экспорт, иначе утонем в конфликтах слияния.


Жду твоих ответов (например: 1-Vue, 2-Б, 3-А, 4-Экспорт), и сразу вывожу полный Project Description с Роадмапом.

React
SaaS
Ответ зависит от того, насколько сложно будет перейти от простого списка к полноценным контейнерам, не придется ли переделывать весь проект? И если мы выбираем SaaS, то может быть правильно было бы здесь выбрать полноценные контейнеры?
Только экспорт.








Принято.


Касательно пункта 3 (Сложность редактора):
Переход от «простого списка» к «контейнерам» в будущем потребует миграции данных (обернуть тысячи старых записей в новые структуры) и переписывания логики рендеринга. Для SaaS-продукта, где пользователи ожидают уровень Notion/Jira, «простой список» будет выглядеть слишком примитивно.
Решение: Закладываем архитектуру «Требование-Контейнер» сразу. С использованием React и библиотеки TipTap это увеличит срок разработки MVP не критично (на 15-20%), но сэкономит месяцы рефакторинга в будущем.


Ниже представлено полное описание проекта, которое послужит контекстом для разработки.



Описание Проекта: AI-Driven Requirements Management System (AI-RMS)

1. Обзор и Цели

Разработка SaaS-платформы для автоматизированного сбора, уточнения и управления требованиями к ПО с использованием Искусственного Интеллекта.
Система использует итеративный подход: ИИ выступает в роли бизнес-аналитика, выявляя неопределенности, задавая вопросы пользователю и генерируя структурированные артефакты (Брифы, ТЗ, User Stories).


Ключевая особенность: Атомарное хранение требований в графовой базе данных с возможностью редактирования через привычный блочный интерфейс (как в Notion).



2. Технологический Стек

Frontend: React (SPA).
UI Kit: Ant Design или Material UI.
Editor Engine: TipTap (на базе ProseMirror) — для реализации блочного редактора с контейнерами.
Middleware / Backend: n8n.
Выполняет роль API Gateway, оркестратора бизнес-логики и интегратора с ИИ.
Database: ArangoDB.
Используется как документ-граф хранилище.
Хранит пользователей, проекты, контент требований и связи между ними.
AI: Подключение по API (OpenAI, Anthropic, etc.) через n8n.


3. Архитектура Данных (ArangoDB)

3.1. SaaS & Доступ (Collections)

Users:
{ _key, email, password_hash, name, role }
Workspaces:
{ _key, name, owner_id }
MemberOf (Edge):
User
->
Workspace
(с правами доступа).

3.2. Проектные данные (Collections)

Projects:
{ _key, workspace_id, name, description }
Documents (Artifacts):
{ _key, project_id, type (brief/srs/user_stories), status, version }
Requirements (Nodes): Атомарные блоки контента.
_key
: UUID.
type
:
requirement_container
(или
heading
,
image
— если вне контейнера).
human_id
: "BR-001" (генерируется для контейнеров).
content
: JSON-структура (для простых блоков) или текст.
metadata
:
{ priority, status, author_id }
.
Structure (Edges):
Document
->
Requirement
(хранит
position
для порядка).
Traceability (Edges):
Requirement
->
Requirement
. Типы:
depends_on
,
refines
,
conflicts_with
.

3.3. Конфигурация (Collections)

AI_Models:
{ _key, name, provider, context_window }
.
Prompts:
{ _key, title, type (system/user), stage, content }
.
Iterations: История генераций для аудита.


4. Пользовательский Интерфейс (UX)

4.1. Основные экраны

Dashboard: Список проектов, создание проекта.
Project Timeline: Визуализация этапов (Бриф -> Бизнес-требования -> Архитектура).
Document Editor: Основное рабочее пространство.

4.2. Логика Редактора (TipTap)

Вид: Выглядит как единый документ.
Структура: Используется кастомный узел
RequirementNode
(Контейнер).
Визуально: Блок с ID сбоку (напр.
BR-005
).
Поведение: Внутри блока работает стандартный Rich Text (параграфы, списки, таблицы).
Создание:
Ctrl+Enter
создает новый контейнер (новое требование).
Синхронизация: При изменении контента React отправляет JSON-патч в n8n, который обновляет конкретный узел
Requirement
в БД.

4.3. Панель Генерации (AI Settings)

Сворачиваемая панель справа или сверху:

Выбор Модели ИИ.
Выбор Системного Промпта (из репозитория).
Редактирование Пользовательского Промпта (шаблон + данные).
Кнопка «Force Submit» (принудительная отправка).


5. Бизнес-процессы (n8n Workflows)

5.1. API Gateway

Единая точка входа для Frontend. Маршрутизирует запросы:

Auth
: Login, Register, Refresh Token.
Data
: CRUD для проектов, документов, промптов.
Process
: Запуск AI-движка.

5.2. AI Engine (Универсальный цикл)

Применим к любому этапу (Бриф, ТЗ, Тесты).


Context Assembly: Сборка контекста из БД (текущий документ + родительские документы).
Ambiguity Check: ИИ ищет пробелы.
Loop: Вопрос -> Ответ пользователя -> Проверка качества -> Повтор.
Generation: ИИ генерирует структуру и контент.
Parsing: n8n разбивает ответ ИИ на атомарные блоки (Requirements) и сохраняет в граф.

5.3. Git Export

По триггеру (кнопка «Экспорт»):

Выгружает структуру документа из ArangoDB.
Собирает Markdown-файл.
Делает Commit/Push в подключенный репозиторий.


6. Roadmap Реализации

Этап 1: MVP Core (Бриф и Уточнение)

Цель: Реализовать цикл "Запрос -> Уточнение -> Результат" в виде текста.
Задачи:
Развернуть ArangoDB и n8n.
Реализовать Workflow авторизации (JWT).
Реализовать Workflow "Ambiguity Loop" (чат-режим).
Frontend: Страница чата и настроек промптов.
Результат сохраняется как простой Markdown-текст (без атомарности пока).

Этап 2: Атомарный Редактор (SaaS Foundation)

Цель: Внедрить TipTap и графовое хранение.
Задачи:
Проектирование схемы
Requirements
и
Structure
в БД.
Разработка React-компонента редактора (Node Views для контейнеров).
API для CRUD операций с блоками.
Миграция текстовых брифов (из Этапа 1) в атомарную структуру.

Этап 3: Управление Требованиями (RMS Features)

Цель: Трассировка и иерархия документов.
Задачи:
Добавление типов документов (SRS, User Stories).
Реализация Context Injection (передача Брифа при генерации SRS).
UI для создания связей (Drag & Drop или меню связей).

Этап 4: Git & Polish

Цель: Интеграция с внешним миром.
Задачи:
Модуль экспорта в Git.
Админка для управления Промптами и Моделями.
Биллинг (если требуется) и управление Workspace.


Этот документ является базовым контекстом для дальнейшей работы.
Для начала реализации (Этап 1 или Проектирование БД) можно переходить в новый чат.

корректировки:

Нужно добавить предоставление доступа пользователям, можно по принципу github - пригласить пользователя в проект (указать емейл пользователя), пользователь должен принять приглашение, и он получит доступ к проекту по одной из ролей: редактор (может редактировать документы, но не настройки проекта) или читатель (может только просматривать результаты).
Новый проект после добавления содержит только один этап от начального ввода текста документа до итога. В настройках проекта можно добавить следующие этапы, выбрать системные и пользовательские промпты из репозитория (нужен классификатор промптов, например: БТ, ФТ, НФТ, UX/UI, API) или добавить свои промпты и назвать следующий этап по-своему, а так же в будущем (не в MVP) построение рейтинга использования промптов, для чего нужно в итерациях хранить uid системного промпта, который был использован для взаимодействия с ИИ (но хранить uid промпта нужно уже в MVP).
Нужна админка для управления пользователями: удалить, заблокировать, разблокировать. Регистрироваться пользователи должны сами. Восстанавливать пароль пока не надо, это будет делать администратор системы. Но пользователь должен иметь возможность сменить пароль в настройках профиля (нужно добавить профиль пользователя).
ArangoDB и n8n должны быть на одном сервере, или могут быть на разных?










Принято. Эти уточнения делают систему более зрелой и готовой к реальному использованию командами.


Ответ на вопрос №4 (Инфраструктура):
ArangoDB и n8n могут находиться на разных серверах.


Вариант "Разные серверы": Это нормально для масштабирования. Главное — настроить сетевой доступ (открыть порт 8529 на сервере БД только для IP-адреса сервера n8n) и использовать надежный пароль.
Вариант "Один сервер" (Рекомендуемый для MVP): Лучше поднять их рядом через Docker Compose. Это упрощает администрирование, исключает сетевые задержки и безопаснее (база данных вообще не смотрит в интернет, общается с n8n по внутренней сети Docker).

Ниже представлено Финальное скорректированное описание проекта.



Описание Проекта: AI-Driven RMS (SaaS Version)

1. Обзор и Цели

SaaS-платформа для совместной разработки требований к ПО. Позволяет командам итеративно создавать документацию (от Брифа до API-спецификаций) с помощью ИИ.
Поддерживает ролевую модель доступа, гибкую настройку этапов проекта и атомарное редактирование требований.



2. Технологический Стек

Frontend: React (SPA) + Ant Design/MUI.
Editor: TipTap (ProseMirror) — блочный редактор с контейнерами.
Backend: n8n (API Gateway + Logic).
Database: ArangoDB (Graph).
Infra: Docker Compose (n8n + ArangoDB на одном хосте для MVP).


3. Архитектура Данных (ArangoDB)

3.1. Пользователи и Доступ

Users:
{ _key, email, password_hash, name, is_blocked, role (user/admin) }
Invites:
{ _key, email, project_id, role, token, status (pending/accepted) }
MemberOf (Edge):
User
->
Project
.
Attributes:
role
(
owner
,
editor
,
reader
).
Editor: Редактирует документы, запускает ИИ.
Reader: Только просмотр.
Owner: Управление настройками проекта и участниками.

3.2. Проекты и Этапы

Projects:
{ _key, name, description, created_at }
Stages:
{ _key, project_id, name, order, prompt_config }
Проект при создании имеет 1 этап (Default). Пользователь добавляет новые этапы вручную.
Documents (Artifacts): Привязаны к Этапу (
stage_id
).
Requirements (Nodes): Атомарные блоки (Контейнеры).
content
: JSON TipTap.
Structure & Traceability: Графовые связи (как описано ранее).

3.3. Промпты и Аналитика

Prompts:
{ _key, title, content, category (BR, FR, NFR, API, UX), is_system (true/false) }
Iterations: История запросов к ИИ.
prompt_uid
: Ссылка на использованный промпт (Обязательно для рейтинга).
model_uid
: Использованная модель.
user_feedback
: (Опционально) оценка качества ответа.


4. Функциональные Требования (UI/UX)

4.1. Профиль и Админка

Профиль пользователя: Изменение имени, Смена пароля (Старый -> Новый).
Панель Администратора (Super Admin):
Таблица всех пользователей.
Действия: Блокировать/Разблокировать, Удалить.
Сброс пароля (ручной ввод нового пароля админом).

4.2. Управление Проектом (Settings)

Команда:
Список участников с ролями.
Кнопка "Пригласить": Ввод Email -> Выбор роли -> Отправка письма (или генерация ссылки).
Настройка Этапов (Workflow):
Список текущих этапов.
Кнопка "Добавить этап":
Ввод названия (напр. "Генерация API").
Выбор Системного Промпта из Репозитория (фильтр по категориям: БТ, ФТ, API...).
Или создание кастомного промпта.

4.3. Рабочее пространство (Editor)

Таймлайн: Динамический (строится на основе добавленных Этапов).
Редактор: Блочный (TipTap).
Для
Reader
— Read-only режим.
Для
Editor
— Full access.


5. Бизнес-процессы (n8n)

5.1. Auth & Users

Register: Самостоятельная регистрация.
Invite Flow:
Create Invite
: Генерирует токен, сохраняет в БД. (Отправка email через SMTP ноду или просто возврат ссылки).
Accept Invite
: Проверяет токен, создает ребро
MemberOf
, удаляет инвайт.
Admin Actions: API для блокировки пользователей.

5.2. AI Logic

Logging: При каждом вызове ИИ в коллекцию
Iterations
записывается
prompt_uid
.
Context: При запуске этапа N, собирается контекст из документов этапов 1...(N-1).


6. Roadmap Реализации

Этап 1: MVP Foundation (Single User + Core)

Инфра: Docker Compose (n8n + Arango).
Backend: Auth (Login/Register), Project CRUD.
AI Core: Цикл "Анализ -> Уточнение" с сохранением истории промптов (
prompt_uid
).
Frontend:
Профиль, Создание проекта.
Чат с ИИ (текстовый режим, без сложного редактора пока).
Админка (базовая таблица).

Этап 2: Editor & Collaboration

Editor: Внедрение TipTap (Атомарные требования).
Access: Реализация системы инвайтов и ролей (Editor/Reader).
Stages: Реализация динамического добавления этапов в настройках проекта.

Этап 3: Advanced Features

Repo: Классификатор промптов в UI, фильтры.
Traceability: Связи между требованиями разных этапов.
Analytics: Построение рейтинга промптов на основе данных из
Iterations
.


Этот документ полностью готов к использованию как ТЗ для разработки.

Настройка Этапов (Workflow):

нужно добавить функцию удаления этапа









Принято. Функция удаления этапа критична для гибкости настройки процесса.


Добавил этот пункт в раздел 4.2. Управление Проектом. Также учел, что при удалении этапа нужно пересчитывать порядок (
order
) оставшихся этапов.


Вот итоговая, зафиксированная версия описания проекта, с которой можно переходить к реализации (проектированию БД и API).



Описание Проекта: AI-Driven RMS (SaaS Version)

1. Обзор и Цели

SaaS-платформа для совместной разработки требований к ПО. Позволяет командам итеративно создавать документацию (от Брифа до API-спецификаций) с помощью ИИ.
Поддерживает ролевую модель доступа, гибкую настройку этапов проекта и атомарное редактирование требований.



2. Технологический Стек

Frontend: React (SPA) + Ant Design/MUI.
Editor: TipTap (ProseMirror) — блочный редактор с контейнерами.
Backend: n8n (API Gateway + Logic).
Database: ArangoDB (Graph).
Infra: Docker Compose (n8n + ArangoDB на одном хосте для MVP).


3. Архитектура Данных (ArangoDB)

3.1. Пользователи и Доступ

Users:
{ _key, email, password_hash, name, is_blocked, role (user/admin) }
Invites:
{ _key, email, project_id, role, token, status (pending/accepted) }
MemberOf (Edge):
User
->
Project
.
Attributes:
role
(
owner
,
editor
,
reader
).
Editor: Редактирует документы, запускает ИИ.
Reader: Только просмотр.
Owner: Управление настройками проекта и участниками.

3.2. Проекты и Этапы

Projects:
{ _key, name, description, created_at }
Stages:
{ _key, project_id, name, order, prompt_config }
Проект при создании имеет 1 этап (Default). Пользователь добавляет новые этапы вручную.
Documents (Artifacts): Привязаны к Этапу (
stage_id
).
Requirements (Nodes): Атомарные блоки (Контейнеры).
content
: JSON TipTap.
Structure & Traceability: Графовые связи (как описано ранее).

3.3. Промпты и Аналитика

Prompts:
{ _key, title, content, category (BR, FR, NFR, API, UX), is_system (true/false) }
Iterations: История запросов к ИИ.
prompt_uid
: Ссылка на использованный промпт (Обязательно для рейтинга).
model_uid
: Использованная модель.
user_feedback
: (Опционально) оценка качества ответа.


4. Функциональные Требования (UI/UX)

4.1. Профиль и Админка

Профиль пользователя: Изменение имени, Смена пароля (Старый -> Новый).
Панель Администратора (Super Admin):
Таблица всех пользователей.
Действия: Блокировать/Разблокировать, Удалить.
Сброс пароля (ручной ввод нового пароля админом).

4.2. Управление Проектом (Settings)

Команда:
Список участников с ролями.
Кнопка "Пригласить": Ввод Email -> Выбор роли -> Отправка письма (или генерация ссылки).
Настройка Этапов (Workflow):
Список текущих этапов (Drag & Drop для сортировки).
Кнопка "Добавить этап":
Ввод названия (напр. "Генерация API").
Выбор Системного Промпта из Репозитория (фильтр по категориям: БТ, ФТ, API...).
Или создание кастомного промпта.
Удаление этапа: Кнопка "Удалить". Требует подтверждения, если этап содержит данные.

4.3. Рабочее пространство (Editor)

Таймлайн: Динамический (строится на основе добавленных Этапов).
Редактор: Блочный (TipTap).
Для
Reader
— Read-only режим.
Для
Editor
— Full access.


5. Бизнес-процессы (n8n)

5.1. Auth & Users

Register: Самостоятельная регистрация.
Invite Flow:
Create Invite
: Генерирует токен, сохраняет в БД.
Accept Invite
: Проверяет токен, создает ребро
MemberOf
, удаляет инвайт.
Admin Actions: API для блокировки пользователей.

5.2. AI Logic

Logging: При каждом вызове ИИ в коллекцию
Iterations
записывается
prompt_uid
.
Context: При запуске этапа N, собирается контекст из документов этапов 1...(N-1).


6. Roadmap Реализации

Этап 1: MVP Foundation (Single User + Core)

Инфра: Docker Compose (n8n + Arango).
Backend: Auth (Login/Register), Project CRUD.
AI Core: Цикл "Анализ -> Уточнение" с сохранением истории промптов (
prompt_uid
).
Frontend:
Профиль, Создание проекта.
Чат с ИИ (текстовый режим, без сложного редактора пока).
Админка (базовая таблица).

Этап 2: Editor & Collaboration

Editor: Внедрение TipTap (Атомарные требования).
Access: Реализация системы инвайтов и ролей (Editor/Reader).
Stages: Реализация динамического добавления и удаления этапов в настройках проекта.

Этап 3: Advanced Features

Repo: Классификатор промптов в UI, фильтры.
Traceability: Связи между требованиями разных этапов.
Analytics: Построение рейтинга промптов на основе данных из
Iterations
.


Следующий шаг: Можно открывать новый чат и приступать к детальному проектированию схемы базы данных ArangoDB (коллекции, индексы, AQL-запросы) на основе этого описания.

мало подробностей. Нет описания workflow уточнения и генерации, итеративной проверки ответов на уточняющие вопросы, эти подробности потерялись по дороге, а это самая мякотка, и влияет на интерфейс - нужно вводить ответы на вопросы, полученные от ИИ.








Ты абсолютно прав. Я слишком сильно «сжал» описание в погоне за краткостью, и потерял ключевую логику взаимодействия, которую мы прорабатывали в самом начале. А ведь именно этот цикл (Проверка -> Вопросы -> Ответы -> Качество -> Генерация) диктует структуру интерфейса.


Возвращаю полную детализацию Workflow в описание проекта.



Описание Проекта: AI-Driven RMS (Full Context)

1. Обзор и Цели

SaaS-платформа для итеративной разработки требований к ПО.
Ядро системы: Интеллектуальный агент, который не просто генерирует текст, а выступает в роли дотошного аналитика: находит неопределенности, задает уточняющие вопросы, проверяет качество ответов пользователя и только потом формирует финальный артефакт.



2. Технологический Стек

Frontend: React (SPA) + Ant Design/MUI.
Editor: TipTap (ProseMirror) — блочный редактор.
Backend: n8n (API Gateway + Logic).
Database: ArangoDB (Graph).
Infra: Docker Compose.


3. Архитектура Данных (ArangoDB)

(Без изменений: Users, Invites, Projects, Stages, Documents, Requirements, Prompts, Iterations)



4. Детальный Workflow Генерации (The Core)

Этот процесс универсален и запускается на любом этапе (Бриф, ФТ, API), меняются только промпты.


Шаг 1: Инициализация и Анализ

UI: Пользователь вводит исходный текст (или он берется из предыдущего этапа).
Action: Отправка текста + настройки этапа (ID модели, ID системного промпта) в n8n.
AI (Ambiguity Check): Анализирует текст на неопределенности.
Вход: Текст + Системный Промпт (из настроек этапа).
Выход: JSON со статусом (
clean
/
ambiguous
) и списком вопросов.
Logic:
Если
clean
-> Переход к Шагу 3 (Генерация).
Если
ambiguous
-> Переход к Шагу 2 (Q&A).

Шаг 2: Цикл Уточнения (Q&A Loop)

Самая сложная часть интерфейса.


UI (Форма вопросов):
Отображает список вопросов от ИИ.
Поля ввода ответов для каждого вопроса.
Кнопка «Отправить ответы» (Заблокирована, пока не заполнены все поля).
Кнопка «Force Submit» (Принять ответы без проверки) — с предупреждением.
Action: Пользователь отправляет ответы.
AI (Quality Check): Проверяет содержательность ответов.
Вход: Пары Вопрос-Ответ + Промпт проверки качества.
Выход: JSON (
pass
/
fail
) + массив замечаний (
feedback
).
Logic:
Ветка Force: Пропускаем проверку -> Переход к Шагу 3.
Ветка Normal:
Если
pass
-> Переход к Шагу 3.
Если
fail
-> Возврат на UI.
UI (Обработка ошибок):
Подсвечивает поля с некачественными ответами красным.
Выводит текст замечания ИИ (напр. "Ответ 'да' не подходит, уточните детали").
Блокировка: Не дает отправить повторно, пока пользователь не изменит текст ответа (dirty check).

Шаг 3: Генерация и Ревизия

AI (Refinement): Генерирует итоговый документ.
Вход: Исходный текст + (Вопросы + Ответы) + Контекст проекта + Промпт генерации.
Выход: Структурированный документ (Markdown/JSON).
UI (Редактор):
Отображает сгенерированный документ в TipTap.
Пользователь может вручную поправить текст.
Action: Пользователь нажимает «Утвердить» или «Перегенерировать».
Если «Утвердить» -> Документ сохраняется, этап завершен.


5. Функциональные Требования (UI/UX)

5.1. Интерфейс Q&A (Диалог с ИИ)

Это не просто чат, а структурированная форма:

Карточка вопроса:
Цитата из текста (контекст вопроса).
Текст вопроса.
Поле ввода ответа.
Индикатор качества (Галочка / Красный крест с пояснением).
История итераций: Возможность развернуть предыдущие попытки ответов (если ИИ их отверг).

5.2. Управление Проектом

Настройка Этапов:
Drag & Drop сортировка этапов.
Добавление этапа: Выбор категории (БТ, API...), Выбор Промпта из Репозитория.
Удаление этапа (с подтверждением).
Команда: Инвайты по Email, Роли (Editor/Reader).

5.3. Редактор (TipTap)

Поддержка вложенных контейнеров (Требование).
Визуализация ID требований (
BR-001
).


6. Бизнес-процессы (n8n)

6.1. Process Brief (Main Workflow)

Единый роутер, обрабатывающий состояния:

analyze
: Запуск проверки на неопределенность.
check_answers
: Валидация ответов (с ветвлением Force/Normal).
generate
: Финальная сборка документа.
Логирование: Каждый шаг пишет лог в коллекцию
Iterations
(какой промпт, какая модель, какой юзер).

6.2. Auth & Admin

Регистрация, Инвайты, Блокировка пользователей.


7. Roadmap Реализации

Этап 1: MVP Core (Single User + Q&A Logic)

Focus: Реализация "Мякотки" — цикла уточнения.
Tasks:
n8n Workflow для Ambiguity & Quality Check.
Frontend: Форма Q&A с валидацией и отображением ошибок от ИИ.
Frontend: Кнопка Force Submit.
ArangoDB: Хранение истории итераций.

Этап 2: SaaS Foundation

Focus: Пользователи и Проекты.
Tasks:
Auth (JWT), Invites.
Настройка этапов проекта (Add/Delete Stage).
Репозиторий промптов (выбор в UI).

Этап 3: Advanced Editor

Focus: Атомарность.
Tasks:
Внедрение TipTap.
Контейнерные требования.
Графовые связи в БД.


Теперь описание содержит все детали логики уточнения, валидации и интерфейса ответов. Можно переходить к проектированию.

нужно добавить Шаг 4: сверка с исходным заданием с помощью ИИ, не упущено ли что из первоначального документа, чтобы ИИ показал изменения -что добавлено, что убрано, что уточнено из первоначального документа, для этого нужен свой системный промпт
плюс на начальном этапе (и на промежуточных) должна быть возможность добавления файлов к промпту, с проверкой ограничений на общий размер всех приложенных файлов в зависимости от выбранной модели (эти ограничения должны быть указаны при настройке подключения модели ИИ к n8n и где-то храниться... в БД?)









Отличные дополнения.


Сверка (Compliance Check) — это критически важный этап для контроля качества, чтобы ИИ в порыве "творчества" не выкинул важные требования заказчика.
Файлы — обязательная функция, так как ТЗ часто начинается с кучи PDF/Word документов.

Вношу изменения в описание.



Описание Проекта: AI-Driven RMS (Final v3)

1. Обзор и Цели

SaaS-платформа для итеративной разработки требований к ПО.
Ядро системы: Интеллектуальный агент, который анализирует неопределенности, валидирует ответы пользователя, генерирует артефакты и сверяет их с исходными данными, гарантируя полноту требований.



2. Технологический Стек

Frontend: React (SPA) + TipTap (Editor).
Backend: n8n (Logic) + Docker (File Parsing).
Database: ArangoDB.


3. Архитектура Данных (ArangoDB)

3.1. Конфигурация и Лимиты

AI_Models:
_key
: ID модели (
gpt-4-turbo
,
claude-3-opus
).
provider
:
openai
,
anthropic
.
context_window
: Лимит токенов (напр.
128000
).
max_output_tokens
: Лимит генерации.
Prompts: Добавляется категория
Compliance Check
.

3.2. Файлы

Attachments:
{ _key, project_id, stage_id, filename, file_type, parsed_text_content, size_tokens }
.


4. Детальный Workflow (The Core)

Шаг 0: Ввод данных и Файлы

UI: Пользователь вводит текст + Прикрепляет файлы (PDF, DOCX, TXT).
Validation (Client/Server):
n8n парсит файлы в текст.
Считает примерное кол-во токенов (Текст + Файлы).
Сравнивает с
context_window
выбранной модели.
Ошибка: Если превышен лимит -> UI просит убрать файлы или выбрать модель с большим окном (напр. Claude 3 200k).

Шаг 1: Анализ (Ambiguity)

(Без изменений: Поиск неопределенностей -> JSON)


Шаг 2: Цикл Уточнения (Q&A Loop)

(Без изменений: Вопросы -> Ответы -> Проверка качества -> Force Submit)


Шаг 3: Генерация (Refinement)

(Без изменений: Генерация документа на основе ответов)


Шаг 4: Сверка (Compliance Check) — NEW

Автоматический аудит результата перед показом пользователю.


Action: n8n отправляет в ИИ:
Original Input
(Текст + Файлы из Шага 0).
Generated Output
(Результат Шага 3).
System Prompt
: "Сравни документы. Составь отчет: что добавлено, что удалено, что уточнено. Проверь, не потеряны ли критические требования."
AI: Генерирует Diff Report (JSON или Markdown).
UI:
Показывает сгенерированный документ (в Редакторе).
Рядом (в сайдбаре или модалке): Отчет о сверке.
🟢 Добавлено: Детали авторизации...
🟡 Уточнено: Стек технологий...
🔴 Внимание (Упущено?): Не найдено упоминание мобильной версии, хотя в исходнике было.
Decision: Пользователь читает отчет и решает: «Принять» или «Отправить на доработку» (вручную или через комментарий ИИ).


5. Функциональные Требования (UI/UX)

5.1. Работа с файлами

Upload Zone: Drag & Drop.
Token Meter: Визуальная шкала «Заполнено контекста: 45%». Если >100% — блокировка отправки.
File Preview: Возможность просмотреть распаршенный текст (чтобы убедиться, что PDF прочитался корректно).

5.2. Отчет о сверке (Diff View)

Отдельная панель "AI Audit".
Цветовое кодирование (Зеленый/Желтый/Красный).
Кнопка "Исправить автоматически" (опционально) — просит ИИ вернуть упущенное.


6. Бизнес-процессы (n8n)

6.1. File Processing

Новый Workflow или Sub-workflow.
Использует ноды (или внешние утилиты) для экстракции текста из PDF/DOCX.
Расчет токенов (можно использовать грубую оценку: 1 слово ≈ 1.3 токена, или библиотеку
tiktoken
в Function Node).

6.2. Compliance Workflow

Вызывается после успешной генерации.
Не блокирует процесс, но добавляет метаданные к результату.


7. Roadmap Реализации

Этап 1: MVP Core

Files: Загрузка простых TXT/MD файлов. Проверка лимитов.
Compliance: Простой текстовый отчет от ИИ ("Что изменилось") в конце генерации.

Этап 2: Advanced Input

Files: Парсинг PDF/DOCX (OCR не нужен, только текст).
Token Meter: Точный подсчет токенов в UI.


Теперь описание включает полный цикл контроля качества: от входных лимитов до финальной сверки. Можно приступать к реализации.

нет, неполное описание, пропали некоторые разделы из предыдущих версий итогового документа, в каких-то разделах описание опущено.
Давай писать подробное описание по разделам отдельно, сначала раздел 1, потом раздел 2 и т.п. И напиши всё без сокращений и упущений.


Всего должно быть 7 разделов:

Обзор и Цели
Технологический Стек
Архитектура Данных (ArangoDB)
Детальный Workflow Генерации (The Core)
Функциональные Требования (UI/UX)
Бизнес-процессы (n8n)
Roadmap Реализации Выведи сейчас максимально подробно раздел 1. Обзор и Цели






Принято. Такой подход (посекционный вывод) гарантирует, что мы зафиксируем каждую деталь без сокращений.


Начинаем.



Раздел 1. Обзор и Цели

1.1. Название и Суть Проекта

Проект: AI-Driven Requirements Management System (AI-RMS).
Тип: SaaS-платформа (Software as a Service).


Это система для автоматизированной и совместной разработки требований к программному обеспечению. В отличие от обычных чат-ботов (ChatGPT), которые просто генерируют текст, данная платформа реализует агентный подход: ИИ выступает в роли квалифицированного бизнес-аналитика, который ведет пользователя по строгому процессу выявления требований, не допуская создания поверхностных или противоречивых документов.


1.2. Основные Цели

Устранение неопределенности: Автоматическое выявление "серых зон" в запросах заказчика до начала разработки. Система не позволяет перейти к генерации ТЗ, пока не будут разрешены критические смысловые пробелы.
Структуризация знаний: Переход от хранения требований в виде монолитных текстовых файлов (Word/Google Docs) к атомарной графовой структуре. Каждое требование — это отдельный объект базы данных, что позволяет отслеживать связи, версии и статус каждого конкретного пункта.
Контроль качества (Compliance): Гарантия того, что итоговый документ соответствует исходному запросу. ИИ выполняет роль аудитора, сверяя результат с исходными данными и подсвечивая любые отклонения или упущения.
Гибкость процесса: Возможность настраивать цепочку производства документации (Workflow) под конкретный проект — от простого "Брифа" до сложной цепочки "Бизнес-требования -> Функциональные требования -> API Спецификация" с использованием специализированных промптов.

1.3. Ключевые Возможности

Итеративный диалог: Умный цикл "Анализ -> Вопросы -> Проверка ответов -> Генерация", который заставляет пользователя давать качественные входные данные.
SaaS и Коллаборация: Многопользовательский доступ, разделение на проекты и воркспейсы, ролевая модель (Редактор/Читатель), система приглашений.
Блочный Редактор (Block Editor): Современный интерфейс редактирования (аналог Notion/Confluence), который скрывает от пользователя сложность графовой базы данных, предоставляя привычный опыт работы с документом.
Работа с контекстом: Поддержка загрузки файлов (PDF, DOCX) и автоматический контроль лимитов контекстного окна выбранной модели ИИ.


Раздел 1 утвержден? Переходим к Разделу 2 (Технологический Стек)?

Утвержден. Переходим к разделу 2








Раздел 2. Технологический Стек

Для реализации проекта выбран стек, обеспечивающий баланс между гибкостью разработки (Low-Code для логики) и производительностью интерфейса (React для UI).


2.1. Frontend (Клиентская часть)

Фреймворк: React (Single Page Application).
Обеспечивает реактивность интерфейса, необходимую для сложного редактора и чата.
UI Библиотека: Ant Design или Material UI (MUI).
Готовый набор компонентов (таблицы, модальные окна, формы, уведомления) для ускорения разработки админки и настроек.
Ядро Редактора: TipTap (на базе ProseMirror).
Headless-редактор, позволяющий полностью кастомизировать рендеринг блоков.
Критически важен для реализации концепции «Требование-Контейнер» и привязки уникальных ID к блокам текста.
Стейт-менеджмент: Redux Toolkit или Zustand (для хранения состояния сессии, загруженных файлов и кэша документов).

2.2. Backend / Middleware (Бизнес-логика)

Платформа: n8n (Workflow Automation Tool).
Выполняет роль API Gateway: Принимает все REST-запросы от Frontend.
Выполняет роль Orchestrator: Управляет логикой авторизации, валидации данных, вызовами ИИ и записью в БД.
Позволяет быстро менять логику обработки промптов без пересборки кода.
Обработка файлов: Встроенные ноды n8n или внешние утилиты (в Docker-контейнере) для парсинга PDF/DOCX в чистый текст.

2.3. Database (Хранение данных)

СУБД: ArangoDB.
Тип: Мультимодельная (Document + Graph).
Роль: Единое хранилище для всех данных.
Использование Графов: Для хранения связей (Traceability) между требованиями, пользователями и проектами.
Использование Документов: Для хранения профилей пользователей, конфигураций и контента требований (JSON).

2.4. AI & Integration (Искусственный Интеллект)

Провайдеры: Подключение по API (OpenAI, Anthropic, Google Gemini и др.).
Управление: Настройка ключей и параметров моделей (temperature, top_p) осуществляется внутри n8n (Credentials) или через базу данных (для выбора модели в UI).

2.5. Infrastructure (Инфраструктура)

Среда: Docker Compose.
Контейнер 1:
n8n
(Бэкенд).
Контейнер 2:
arangodb
(База данных).
Контейнер 3:
frontend
(Nginx, раздающий статику React-приложения).
Сетевое взаимодействие:
Frontend обращается к n8n через публичный порт (напр. 443/5678).
n8n обращается к ArangoDB через внутреннюю сеть Docker (порт 8529), база данных не доступна извне напрямую.


Раздел 2 утвержден? Переходим к Разделу 3 (Архитектура Данных)?

Утвержден. Переходим к Разделу 3.








Раздел 3. Архитектура Данных (ArangoDB)

База данных спроектирована с использованием коллекций документов (Document Collections) и коллекций ребер (Edge Collections) для реализации графовых связей.


3.1. Пользователи и Доступ (SaaS Core)

Document Collections:

Users (Пользователи):

_key
: UUID пользователя.
email
: Email (уникальный индекс).
password_hash
: Хеш пароля (bcrypt/argon2).
name
: Отображаемое имя.
role
: Роль в системе (
user
,
admin
).
is_blocked
: Boolean (статус блокировки).
created_at
: Timestamp.
Invites (Приглашения):

_key
: UUID приглашения.
email
: Email приглашенного.
project_id
: ID проекта, куда приглашают.
role
: Роль в проекте (
editor
,
reader
).
token
: Уникальный токен для ссылки активации.
status
:
pending
,
accepted
,
expired
.
expires_at
: Дата истечения срока действия.

Edge Collections:

MemberOf (Членство):
_from
:
Users/{id}
_to
:
Projects/{id}
role
: Роль пользователя в конкретном проекте (
owner
,
editor
,
reader
).

3.2. Структура Проекта

Document Collections:

Projects (Проекты):

_key
: UUID проекта.
name
: Название.
description
: Описание.
created_by
: ID создателя.
created_at
: Timestamp.
Stages (Этапы):

_key
: UUID этапа.
project_id
: Ссылка на проект (для быстрой фильтрации).
name
: Название этапа (напр. "Бизнес-требования").
order
: Integer (порядковый номер сортировки).
prompt_config
: Объект настроек (ID выбранного системного промпта, ID модели).
Documents (Артефакты):

_key
: UUID документа.
stage_id
: Ссылка на этап.
project_id
: Ссылка на проект.
type
: Тип документа (
brief
,
srs
,
api_spec
,
user_stories
).
status
:
draft
,
processing
,
review
,
completed
.
version
: Номер версии.

Edge Collections:

DocLink (Связь этапов):
_from
:
Documents/{prev_doc_id}
_to
:
Documents/{next_doc_id}
Определяет, на основе какого документа создан текущий (Lineage).

3.3. Контент Требований (Atomic Content)

Document Collections:

Requirements (Атомарные требования):
_key
: UUID требования.
human_id
: Читаемый ID (напр. "BR-001", генерируется системой).
type
:
container
(основной тип),
heading
,
image
.
content
: JSON-структура (TipTap Content) — хранит текст, списки, таблицы внутри этого требования.
metadata
:
{ author_id, priority, status }
.
quality_score
: Оценка качества от ИИ (опционально).

Edge Collections:

Structure (Структура документа):

_from
:
Documents/{id}
_to
:
Requirements/{id}
position
: Integer (порядок следования в документе).
Traceability (Трассировка):

_from
:
Requirements/{source_id}
_to
:
Requirements/{target_id}
type
: Тип связи (
depends_on
,
refines
,
conflicts_with
,
verifies
).

3.4. Конфигурация и Логи

Document Collections:

AI_Models (Модели ИИ):

_key
: ID модели (напр.
gpt-4o
).
name
: Отображаемое имя.
provider
:
openai
,
anthropic
,
ollama
.
context_window
: Лимит токенов (напр. 128000).
max_output_tokens
: Лимит генерации.
Prompts (Репозиторий промптов):

_key
: UUID промпта.
title
: Название.
content
: Текст промпта (с плейсхолдерами
{{text}}
).
category
: Классификатор (
BR
,
FR
,
NFR
,
API
,
UX
,
Compliance
).
is_system
: Boolean (системный или пользовательский шаблон).
Iterations (История/Логи):

_key
: UUID итерации.
project_id
: ID проекта.
stage_id
: ID этапа.
prompt_uid
: Ссылка на использованный промпт (для аналитики).
model_uid
: Ссылка на модель.
input_tokens
: Кол-во токенов.
output_tokens
: Кол-во токенов.
timestamp
: Время.
Attachments (Файлы):

_key
: UUID файла.
project_id
: ID проекта.
filename
: Имя файла.
file_type
: MIME type.
parsed_text
: Извлеченный текст (для отправки в контекст ИИ).
size_tokens
: Размер в токенах.


Раздел 3 утвержден? Переходим к Разделу 4 (Детальный Workflow)?

есть замечания к разделу.


у этапа есть:

prompt_config
: Объект настроек (ID выбранного системного промпта, ID модели).


но внутри этапа могут быть разные системные промпты, в зависимости от операции:

для поиска неопределенностей и составления списка вопросов - один системный промпт
для проверки качества ответов - другой системный промпт
для генерации уточненного документа - третий системный промпт
для проверки качества сгенерированного документа - четвертый системный промпт И этих промптов может быть несколько вариантов, на разных языках. Это не отражено в структуре данных. типы документов, статусы, роли, типы промптов, провайдеры ИИ, классификатор промптов, типы файлов - для этого не нужно заводить отдельные справочники? Это будет хардкод в UI?





{
  "ambiguity_prompt_id": "uuid",
  "quality_check_prompt_id": "uuid",
  "generation_prompt_id": "uuid",
  "compliance_prompt_id": "uuid"
}


Справедливые замечания. Текущая структура
prompt_config
 действительно не покрывает сложность процесса, где на каждом шаге нужен свой специализированный промпт. Также согласен, что хардкодить списки (enum) в коде — плохая практика для расширяемой системы, лучше вынести их в справочники.


Вношу корректировки в Раздел 3.



Раздел 3. Архитектура Данных (ArangoDB) — Исправленная версия

3.1. Справочники (System Dictionaries)

Чтобы избежать хардкода в UI и обеспечить гибкость, создаем коллекцию для хранения списков значений.


Document Collections:

Dictionaries (Справочники):
Хранит документы-списки. Пример документов внутри:
{ _key: "prompt_categories", values: ["БТ", "ФТ", "API", "UX", "Compliance"] }
{ _key: "document_types", values: ["Brief", "SRS", "UserStories", "TestCases"] }
{ _key: "file_types", values: ["pdf", "docx", "txt", "md"] }
{ _key: "ai_providers", values: ["openai", "anthropic", "google"] }
{ _key: "user_roles", values: ["owner", "editor", "reader"] }

3.2. Пользователи и Доступ

(Без изменений, но поля
role
 теперь валидируются по справочнику
user_roles
)


Users:
{ _key, email, password_hash, name, role, is_blocked }
Invites:
{ _key, email, project_id, role, token, status }
MemberOf (Edge):
User
->
Project
(
role
).

3.3. Структура Проекта и Конфигурация Этапов

Document Collections:

Projects:
{ _key, name, description, created_by, created_at }

Stages (Этапы):

Структура настроек расширена для поддержки всех шагов Workflow.
_key
: UUID этапа.
project_id
: Ссылка на проект.
name
: Название.
order
: Порядковый номер.
config
:
model_id
: ID модели ИИ для этого этапа.
prompts
:
ambiguity_check_id
: ID промпта для поиска неопределенностей.
answer_quality_check_id
: ID промпта для проверки ответов пользователя.
generation_id
: ID промпта для генерации финального документа.
compliance_check_id
: ID промпта для сверки с исходником.
Documents:
{ _key, stage_id, type (из справочника), status, version }


Edge Collections:


DocLink:
Document
->
Document
.

3.4. Контент Требований

(Без изменений)


Requirements:
{ _key, human_id, type, content, metadata }
Structure (Edge):
Document
->
Requirement
.
Traceability (Edge):
Requirement
->
Requirement
.

3.5. Конфигурация ИИ и Логи

Document Collections:

AI_Models:

_key
: ID модели.
provider
: (из справочника
ai_providers
).
context_window
: Число.
max_output_tokens
: Число.
Prompts (Репозиторий промптов):

_key
: UUID промпта.
title
: Название.
content
: Текст шаблона.
category
: (из справочника
prompt_categories
).
target_step
: Для какого шага предназначен (
ambiguity
,
quality
,
generation
,
compliance
).
language
: Язык промпта (
ru
,
en
).
is_system
: Boolean.
Iterations (Логи):

_key
: UUID.
stage_id
: ID этапа.
step_type
: Тип шага (
ambiguity
,
generation
...).
prompt_uid
: Ссылка на использованный промпт.
model_uid
: Ссылка на модель.
input_tokens
: Число.
output_tokens
: Число.
Attachments:
{ _key, project_id, filename, parsed_text, size_tokens }



Теперь Раздел 3 утвержден? Переходим к Разделу 4 (Детальный Workflow)?

в 2. Stages (Этапы):

prompts
:
ambiguity_check_id
: ID промпта для поиска неопределенностей.
answer_quality_check_id
: ID промпта для проверки ответов пользователя.
generation_id
: ID промпта для генерации финального документа.
compliance_check_id
: ID промпта для сверки с исходником.
Лучше сделать универсально, не хардкодить типы промптов.
Например, для генерации БТ на основе уточненного запроса, на вход поступит уточненный запрос, и ИИ будет на первой части этапа не проверять неопределенности, а генерировать БТ в соответствии с системным промптом и дополнительным к промпту шаблоном БТ (они могут быть разные - бизнес-кейс, документ о концепции и границах проекта и т.п.). Т.е. этапы могут состоять разных частей, проверка неопределенностей может отсутствовать, может присутствовать поиск несоответствий между требованиями и что-то еще.
Для MVP можно не делать интерфейс для настройки частей этапа, а править напрямую в БД. Но БД должна быть спроектирована с учетом такой возможности - делать части этапов разными (добавлять новые / удалять старые части).
Или лучше захардкодить?









[
  {
    "step_type": "ambiguity_check",
    "prompt_id": "uuid-1",
    "order": 1,
    "config": { ... }
  },
  {
    "step_type": "generation",
    "prompt_id": "uuid-2",




Однозначно лучше не хардкодить.
Если мы сейчас жестко пропишем поля
ambiguity_id
,
generation_id
, то при добавлении нового типа проверки (например, "Проверка на безопасность" или "Стилевая коррекция") нам придется менять схему БД и переписывать бэкенд.


Поскольку вы ставите цель сделать гибкую систему (SaaS), архитектура должна позволять конструировать Workflow из кубиков. Даже если в MVP мы будем собирать эти кубики вручную в БД, структура должна быть универсальной.


Переделываем структуру
Stages
 на массив шагов.



Раздел 3. Архитектура Данных (ArangoDB) — Финальная версия (Flexible Workflow)

3.1. Справочники (System Dictionaries)

Добавляем типы шагов.


Dictionaries:
{ _key: "step_types", values: ["ambiguity_loop", "simple_generation", "quality_gate", "compliance_check", "traceability_scan"] }
{ _key: "prompt_categories", ... }
и другие.

3.2. Пользователи и Доступ

(Без изменений)


3.3. Структура Проекта и Гибкие Этапы

Projects:
{ _key, name, description... }

Stages (Этапы):

_key
: UUID этапа.
project_id
: Ссылка на проект.
name
: Название.
order
: Порядковый номер.
default_model_id
: ID модели (можно переопределить внутри шага).
workflow_steps
(Array): Массив объектов, определяющих логику этапа.
[
  {
    "id": "step_1",
    "type": "ambiguity_loop", // Тип логики (из справочника)
    "prompt_id": "uuid-prompt-1", // Системный промпт для этого шага
    "order": 1,
    "is_required": true
  },
  {
    "id": "step_2",

json

Примечание: Такая структура позволяет создать этап, где есть только генерация (без вопросов), или этап, где есть 3 последовательные проверки.
Documents:
{ _key, stage_id, type, status, version }


3.4. Контент Требований

(Без изменений)


3.5. Конфигурация ИИ и Логи

AI_Models:
{ _key, provider, context_window... }

Prompts:

_key
: UUID.
content
: Текст.
compatible_step_types
: Array (для каких типов шагов подходит этот промпт, напр.
["generation", "simple_generation"]
).
category
,
language
,
is_system
.
Iterations (Логи):

_key
: UUID.
stage_id
: ID этапа.
step_index
: Номер шага внутри этапа (чтобы понимать, на каком шаге workflow мы находимся).
step_type
: Тип шага.
prompt_uid
,
model_uid
,
tokens
...
Attachments:
{ ... }



Теперь структура
Stages
 полностью универсальна. Утверждаем Раздел 3 и переходим к Разделу 4 (Детальный Workflow)?

нет, нужно уточнить названия.
Проект - у него общий workflow, который делится на этапы (stages), каждый этап делится на шаги (steps).
С учетом этого уточнения выведи описание раздела 3 полностью, без сокращений.







Принято. Уточненная иерархия: Проект -> Этапы (Stages) -> Шаги (Steps).
Вывожу Раздел 3 полностью, со всеми коллекциями и полями, без сокращений.



Раздел 3. Архитектура Данных (ArangoDB)

База данных ArangoDB используется в гибридном режиме: коллекции документов для сущностей и коллекции ребер (Edges) для связей.


3.1. Справочники (System Dictionaries)

Коллекция для хранения системных констант и списков, обеспечивающая гибкость настройки без изменения кода.


Document Collection:
Dictionaries


_key
: Уникальный идентификатор справочника (напр.
step_types
).
values
: Массив допустимых строковых значений.
Пример
step_types
:
["ambiguity_loop", "simple_generation", "quality_gate", "compliance_check", "traceability_scan"]
.
Пример
prompt_categories
:
["Business Requirements", "Functional Requirements", "API", "Security", "UX"]
.
Пример
document_types
:
["Brief", "Concept", "SRS", "UserStories", "TestCases"]
.
Пример
user_roles
:
["owner", "editor", "reader"]
.
Пример
ai_providers
:
["openai", "anthropic", "google", "ollama"]
.

3.2. Пользователи и Доступ (Auth & Access)

Document Collection:
Users


_key
: UUID пользователя.
email
: Email адрес (Unique Index).
password_hash
: Хеш пароля.
name
: Отображаемое имя.
is_blocked
: Boolean (блокировка администратором).
created_at
: Timestamp регистрации.

Document Collection:
Invites


_key
: UUID приглашения.
email
: Email приглашенного пользователя.
project_id
: ID проекта, в который приглашают.
role
: Роль, которая будет назначена (
editor
или
reader
).
token
: Уникальный токен для ссылки активации.
status
: Статус приглашения (
pending
,
accepted
,
expired
).
expires_at
: Timestamp истечения срока действия.

Edge Collection:
MemberOf


_from
:
Users/{user_id}
_to
:
Projects/{project_id}
role
: Роль пользователя в данном проекте (валидируется по справочнику
user_roles
).

3.3. Структура Проекта (Hierarchy)

Document Collection:
Projects


_key
: UUID проекта.
name
: Название проекта.
description
: Текстовое описание.
created_by
: ID пользователя-создателя.
created_at
: Timestamp создания.
status
: Статус проекта (
active
,
archived
).

Document Collection:
Stages
 (Этапы)


_key
: UUID этапа.
project_id
: Ссылка на родительский проект.
name
: Название этапа (напр. "Сбор Бизнес-требований").
order
: Integer (порядковый номер этапа в Workflow проекта).
default_model_id
: ID модели ИИ, используемой по умолчанию на этом этапе.
steps
: Массив объектов (Шаги). Каждый объект содержит:
id
: Локальный ID шага (string).
type
: Тип шага (валидируется по справочнику
step_types
).
prompt_id
: Ссылка на
Prompts/{id}
, используемый на этом шаге.
order
: Порядковый номер шага внутри этапа.
is_required
: Boolean (обязателен ли шаг).
config
: JSON-объект с дополнительными параметрами (опционально).

Document Collection:
Documents
 (Артефакты)


_key
: UUID документа.
project_id
: Ссылка на проект.
stage_id
: Ссылка на этап, в рамках которого создан документ.
type
: Тип документа (валидируется по справочнику
document_types
).
status
: Текущий статус (
draft
,
processing
,
review
,
approved
).
version
: Номер версии (Integer).
created_at
: Timestamp.

Edge Collection:
DocLink
 (Связи документов)


_from
:
Documents/{source_doc_id}
(Родительский документ).
_to
:
Documents/{target_doc_id}
(Производный документ).
type
: Тип связи (напр.
source_for
).
Описание: Используется для построения цепочки происхождения (Lineage), чтобы понимать, на основе какого Брифа было создано ТЗ.

3.4. Контент Требований (Atomic Content)

Document Collection:
Requirements


_key
: UUID требования (атомарного блока).
human_id
: Читаемый идентификатор (напр. "BR-005"), уникальный в рамках проекта.
type
: Тип блока (
container
,
heading
,
paragraph
,
image
).
content
: JSON-структура (формат TipTap/ProseMirror) с контентом блока.
metadata
: Объект с метаданными (
priority
,
author_id
,
status
).
quality_score
: Числовая оценка качества требования от ИИ (0-100).

Edge Collection:
Structure
 (Иерархия)


_from
:
Documents/{doc_id}
или
Requirements/{parent_req_id}
.
_to
:
Requirements/{child_req_id}
.
position
: Integer (порядок отображения внутри родителя).
Описание: Формирует дерево документа.

Edge Collection:
Traceability
 (Трассировка)


_from
:
Requirements/{source_id}
.
_to
:
Requirements/{target_id}
.
type
: Тип смысловой связи (
depends_on
,
conflicts_with
,
refines
,
verifies
).

3.5. Конфигурация ИИ и Логи (AI & Logs)

Document Collection:
AI_Models


_key
: ID модели (напр.
gpt-4o
).
name
: Отображаемое имя в UI.
provider
: Провайдер (валидируется по справочнику
ai_providers
).
context_window
: Максимальное количество токенов контекста (Integer).
max_output_tokens
: Лимит токенов на вывод (Integer).
cost_per_1k_tokens
: Стоимость (для биллинга в будущем).

Document Collection:
Prompts


_key
: UUID промпта.
title
: Название промпта.
content
: Текст шаблона промпта (с переменными).
category
: Категория (валидируется по справочнику
prompt_categories
).
compatible_step_types
: Массив типов шагов, где этот промпт применим.
language
: Язык промпта (
ru
,
en
).
is_system
: Boolean (true = системный, false = пользовательский).

Document Collection:
Iterations
 (История запросов)


_key
: UUID записи лога.
project_id
: ID проекта.
stage_id
: ID этапа.
step_type
: Тип шага, на котором произошел вызов.
prompt_uid
: Ссылка на использованный промпт.
model_uid
: Ссылка на использованную модель.
user_id
: Кто инициировал запрос.
input_tokens
: Количество входных токенов.
output_tokens
: Количество выходных токенов.
timestamp
: Время запроса.
user_feedback
: Оценка пользователя (лайк/дизлайк/комментарий).

Document Collection:
Attachments
 (Файлы)


_key
: UUID файла.
project_id
: ID проекта.
stage_id
: ID этапа (к которому прикреплен).
filename
: Оригинальное имя файла.
file_type
: Расширение/MIME-тип.
parsed_text
: Извлеченный текстовый контент (для отправки в ИИ).
size_tokens
: Размер файла в токенах.
uploaded_at
: Timestamp.


Раздел 3 утвержден? Переходим к Разделу 4 (Детальный Workflow)?

все dictionaries (типы, классификаторы - документов, промптов, пользователей, ролей и т.п.) лежат в одной коллекции?








Да, в текущем дизайне Раздела 3 я предложил хранить их в одной коллекции
Dictionaries
.


Почему так сделано:

Простота: В ArangoDB (NoSQL) нет смысла создавать 10 отдельных коллекций, если в каждой из них будет лежать всего по 5-10 документов (например, 3 роли, 5 типов файлов). Это "замусоривает" список коллекций.
Гибкость: Вы можете добавить новый справочник (например, "Языки интерфейса") просто создав один документ, не меняя схему БД и не создавая новую таблицу/коллекцию.
Производительность: Фронтенд может одним запросом забрать все справочники при инициализации приложения.

Как это выглядит внутри:
Коллекция
Dictionaries
 содержит документы. Каждый документ — это отдельный справочник.


Документ 1 (
_key: "user_roles"
):
{
  "values": [
    { "id": "owner", "label": "Владелец", "description": "Полный доступ" },
    { "id": "editor", "label": "Редактор", "description": "Может менять контент" }
  ]
}
json

Документ 2 (
_key: "prompt_categories"
):
{
  "values": ["БТ", "ФТ", "API", "UX"]
}
json


Альтернатива:
Если справочник станет огромным (тысячи записей) или потребует сложных связей, его нужно будет вынести в отдельную коллекцию. Но для типов документов, ролей и категорий подход "Одна коллекция Dictionaries" является стандартом для NoSQL систем.


Оставляем так или хотите разнести по разным коллекциям?

нет, оставляем. Можно приступать к выводу раздела 4.







Принято. Переходим к самому важному разделу — логике работы системы.



Раздел 4. Детальный Workflow Генерации (The Core)

Этот процесс описывает универсальный цикл работы над этапом. Благодаря гибкой настройке этапов (см. Раздел 3), конкретный этап может включать все описанные шаги или только их часть.


Шаг 0: Инициализация и Ввод Данных (Input & Context)

Перед запуском ИИ необходимо подготовить контекст.


Действие пользователя:
Пользователь открывает этап (напр. "Сбор требований").
Вводит исходный текст (или он подтягивается из результата предыдущего этапа).
Загрузка файлов: Пользователь прикрепляет файлы (PDF, DOCX, TXT).
Системная обработка (n8n + Backend):
Парсинг: Система извлекает чистый текст из файлов.
Токенизация: Считается сумма токенов (Введенный текст + Текст файлов + История предыдущих этапов).
Валидация: Проверяется, влезает ли объем в
context_window
модели, назначенной на этот этап.
UI: Если лимит превышен — отображается предупреждение и блокируется кнопка "Запустить".

Шаг 1: Анализ Неопределенностей (Ambiguity Check)

Цель: Не дать ИИ галлюцинировать на неполных данных.


Запуск: Пользователь нажимает "Начать анализ".
AI Request: n8n отправляет контекст + системный промпт
ambiguity_check_id
.
AI Logic: Модель анализирует текст на наличие противоречий, пропущенных логических связей и неясных терминов.
Результат: JSON-структура.
Статус:
CLEAN
(всё понятно) или
AMBIGUOUS
(есть вопросы).
Список вопросов (если
AMBIGUOUS
).
Ветвление:
Если
CLEAN
-> Автоматический переход к Шагу 3 (Генерация).
Если
AMBIGUOUS
-> Переход к Шагу 2 (Интерфейс вопросов).

Шаг 2: Цикл Уточнения (Q&A Loop)

Цель: Получить качественные ответы от пользователя.


UI (Форма вопросов):
Пользователь видит список вопросов.
Для каждого вопроса есть поле ввода ответа.
Кнопка "Отправить ответы" (активна только при заполнении всех полей).
Кнопка "Force Submit" (Принудительно продолжить) — скрыта под спойлером или требует подтверждения ("Я понимаю риски").
Проверка качества (Quality Gate):
Пользователь отправляет ответы.
AI Request: n8n отправляет (Вопрос + Ответ) + системный промпт
answer_quality_check_id
.
AI Logic: ИИ оценивает, является ли ответ информативным (напр. на вопрос "Какая БД?" ответ "Хорошая" — это
FAIL
, ответ "PostgreSQL 15" — это
PASS
).
Обработка результата:
Если FAIL: n8n возвращает список ошибок. UI подсвечивает проблемные поля красным и выводит комментарий ИИ ("Уточните версию базы данных").
Если PASS: Ответы принимаются, система переходит к генерации.
Если Force Submit: Проверка пропускается, ответы принимаются "как есть".

Шаг 3: Генерация Артефакта (Generation)

Цель: Создать структурированный документ.


Сборка контекста:
Исходный текст + Файлы.
История Q&A (Вопросы + Утвержденные ответы).
Родительские документы (из предыдущих этапов).
AI Request: n8n отправляет всё в модель с системным промптом
generation_id
.
Результат:
ИИ генерирует документ в формате Markdown или JSON (для блочного редактора).
Система сохраняет черновик документа в коллекцию
Documents
со статусом
processing
.

Шаг 4: Сверка и Аудит (Compliance Check)

Цель: Убедиться, что ничего не потеряно.


AI Request: Сразу после генерации запускается процесс сверки.
Вход:
Original Input
(Шаг 0) vs
Generated Output
(Шаг 3).
Промпт:
compliance_check_id
.
AI Logic: ИИ ищет расхождения:
Missing: Что было в исходнике, но пропало в итоге.
Added: Что ИИ придумал сам (галлюцинации или логичные дополнения).
Changed: Где смысл был искажен.
UI (Diff View):
Пользователю показывается сгенерированный документ.
Рядом (в сайдбаре) выводится Отчет о сверке.
Пример: "⚠️ В исходном письме упоминалась интеграция с 1С, в ТЗ этот раздел отсутствует."

Шаг 5: Финализация (Final Review)

Ручная правка: Пользователь может отредактировать полученный документ в редакторе TipTap.
Действия:
"Утвердить" (Approve): Документ получает статус
approved
, этап считается завершенным. Открывается доступ к следующему этапу.
"Перегенерировать" (Regenerate): Возврат к Шагу 3 (можно скорректировать ответы или промпт).
"Вернуться к вопросам": Возврат к Шагу 2.


Раздел 4 утвержден? Переходим к Разделу 5 (Функциональные Требования UI/UX)?

тут точно описана универсальная схема настройки этапа из шагов?


Или может быть тут описать все возможные шаги, известные нам на текущий момент, и то как из этих шагов можно выстроить workflow в n8n? И как пример - этап уточнения запроса на разработку из описанных тут шагов, но структура раздела может быть такой:

Описание каждого типа шага (подробное, с описанием взаимодействия с пользовтаелем, UI, n8n, БД)
Пример этапа из типов шагов с кратким описанием взаимодействия c пользователем, UI, n8n и БД?








Согласен. Описание конкретного сценария как "единственного" противоречит нашей гибкой архитектуре. Правильнее описать библиотеку доступных шагов (кирпичиков), из которых n8n может собрать любой процесс.


Переписываю Раздел 4 в предложенной структуре.



Раздел 4. Детальный Workflow и Типы Шагов

В этом разделе описаны атомарные типы шагов, поддерживаемые системой. Логика n8n построена так, что при запуске этапа она считывает массив
steps
 из конфигурации этапа (см. Раздел 3) и последовательно выполняет указанные блоки.


4.1. Библиотека Типов Шагов (Step Types Library)

Ниже перечислены доступные модули логики.


Тип А:
ambiguity_loop
 (Цикл устранения неопределенности)

Самый сложный интерактивный шаг.


Вход: Текст/Контекст + Системный промпт анализа + Системный промпт проверки качества.
Логика (n8n):
ИИ анализирует входные данные.
Если найдены проблемы -> Возвращает JSON с вопросами.
Ожидает ввода пользователя (Webhook/Wait node).
Получив ответы, запускает проверку качества (Quality Gate).
Если качество низкое -> Возвращает ошибку валидации.
Если ОК -> Сохраняет пары "Вопрос-Ответ" в контекст и завершает шаг.
UI:
Отображение списка вопросов.
Форма ввода ответов с валидацией (красная подсветка ошибок).
Кнопка "Force Submit" (пропуск проверки качества).
БД: Запись в
Iterations
(дважды: анализ и проверка).

Тип Б:
simple_generation
 (Генерация)

Шаг создания контента.


Вход: Накопленный контекст (исходник + файлы + ответы из прошлого шага) + Промпт генерации + Шаблон.
Логика (n8n):
Собирает весь контекст в один промпт.
Отправляет запрос в ИИ.
Парсит ответ (Markdown/JSON).
Создает документ в коллекции
Documents
(статус
draft
) и узлы в
Requirements
.
UI:
Индикатор загрузки ("ИИ пишет документ...").
По завершении — обновление редактора текстом.
БД: Создание
Documents
,
Requirements
,
Structure
.

Тип В:
compliance_check
 (Сверка / Аудит)

Шаг контроля качества результата.


Вход: Исходные данные (Input) + Результат генерации (Output) + Промпт сверки.
Логика (n8n):
Отправляет оба текста в ИИ с просьбой найти расхождения.
Получает JSON-отчет (
added
,
missing
,
modified
).
UI:
Сайдбар или модальное окно "Результаты сверки".
Цветовая индикация (Зеленый/Желтый/Красный).
БД: Запись отчета в метаданные документа или временное хранилище сессии.

Тип Г:
manual_review
 (Ручное утверждение)

Шаг остановки процесса до решения человека.


Логика: Процесс n8n встает на паузу (Wait for Trigger).
UI:
Полнофункциональный редактор TipTap.
Кнопки действий: "Утвердить" (переход к след. этапу), "Перегенерировать" (возврат к Типу Б), "Вернуться к вопросам" (возврат к Типу А).


4.2. Пример сборки Этапа: "Уточнение Запроса"

Рассмотрим, как эти "кирпичики" собираются в реальный Workflow для первого этапа проекта.


Конфигурация в БД (
Stages
):


"steps": [
  { "order": 1, "type": "ambiguity_loop", "prompt_id": "p_analysis_v1" },
  { "order": 2, "type": "simple_generation", "prompt_id": "p_brief_gen_v1" },
  { "order": 3, "type": "compliance_check", "prompt_id": "p_audit_v1" },
  { "order": 4, "type": "manual_review" }
]
json


Сценарий выполнения:


Старт: Пользователь вводит "Хочу CRM для пиццерии" и жмет "Запуск".
Шаг 1 (Ambiguity):
Система видит, что запрос слишком короткий.
UI: Показывает вопросы: "Какие роли нужны?", "Нужна ли интеграция с кухней?".
Пользователь отвечает: "Роли: админ, курьер. Кухня: да".
ИИ проверяет ответы -> ОК.
Шаг 2 (Generation):
Система берет "Хочу CRM..." + "Роли: админ..." и генерирует Бриф.
UI: В редакторе появляется красивый документ.
Шаг 3 (Compliance):
ИИ сверяет Бриф с ответами.
UI: Показывает плашку: "✅ Все требования из переписки учтены".
Шаг 4 (Review):
Пользователь читает, правит пару слов и жмет "Утвердить".
Этап завершен.


Раздел 4 утвержден? Переходим к Разделу 5 (Функциональные Требования UI/UX)?

Раздел 4. Утвержден. Давай раздел 5, пожалуйста, будь так любезен сладкий мой.







С удовольствием! Переходим к визуальной части, где вся наша сложная логика встречается с пользователем.



Раздел 5. Функциональные Требования (UI/UX)

Интерфейс системы должен быть чистым, сфокусированным на работе с текстом, но при этом давать понятные инструменты управления ИИ-агентом.


5.1. Общая Компоновка (Layout)

Левая панель (Навигация):
Список проектов.
Внутри проекта: Дерево документов (Артефактов) и Таймлайн этапов.
Настройки проекта (шестеренка).
Профиль пользователя (аватар внизу).
Центральная область (Рабочая зона):
Занимает 70-80% экрана.
Здесь отображается Редактор (TipTap) или Форма Q&A (в зависимости от текущего шага).
Правая панель (AI Assistant & Context):
Сворачиваемая панель.
Отображает: Чат с ИИ (история), Результаты сверки (Compliance Report), Список прикрепленных файлов.

5.2. Интерфейс Q&A (Шаг Ambiguity)

Это не чат, а структурированная форма.


Карточка вопроса:
Текст вопроса от ИИ.
Цитата из контекста (почему возник вопрос).
Textarea
для ответа.
Валидация:
При попытке отправки пустых полей — блокировка.
При возврате ошибки от Quality Gate — поле подсвечивается красным, снизу выводится текст ошибки ("Ответ слишком короткий").
Управление:
Кнопка "Отправить ответы" (Primary).
Кнопка "Force Submit" (Secondary, требует подтверждения в модальном окне).
История: Возможность развернуть прошлые итерации (вопрос-ответ), если они были отвергнуты.

5.3. Блочный Редактор (TipTap)

Основной инструмент работы с документом.


Визуализация Блоков:
При наведении на блок (параграф/заголовок) слева появляется
Handle
(ручка) для перетаскивания.
Уникальные ID требований (
BR-001
) отображаются мелким шрифтом на полях (Gutter) или как Badges рядом с блоком.
Контейнеры:
Визуальная рамка вокруг требования-контейнера.
Возможность вкладывать контент (списки, картинки) внутрь контейнера.
Режим Read-only:
Для пользователей с ролью
Reader
или для завершенных этапов — редактирование отключено, панель инструментов скрыта.

5.4. Панель "Файлы и Контекст"

Upload Zone: Область Drag & Drop для загрузки PDF/DOCX.
Token Meter (Индикатор токенов):
Прогресс-бар:
[====..] 45%
.
Показывает, сколько места в контекстном окне модели занимают текущие файлы и текст.
При переполнении (>100%) становится красным и блокирует запуск этапа.
Список файлов: Имя, размер, иконка удаления.

5.5. Настройки Проекта (Project Settings)

Вкладка "Workflow":
Список этапов в виде карточек.
Drag & Drop для изменения порядка.
Кнопка "Добавить этап": Модальное окно с выбором шаблона (БТ, API) или созданием кастомного.
Кнопка "Удалить этап" (с иконкой корзины и подтверждением).
Вкладка "Команда":
Таблица участников: Email, Роль, Статус.
Кнопка "Пригласить": Поле ввода Email + Выпадающий список Роли.

5.6. Админка и Профиль

Профиль: Форма смены имени и пароля.
Admin Dashboard:
Таблица пользователей (поиск, фильтры).
Действия: "Заблокировать", "Сбросить пароль".


Раздел 5 утвержден? Переходим к Разделу 6 (Бизнес-процессы n8n)?

5.1.


"Центральная область (Рабочая зона):

Занимает 70-80% экрана.
Здесь отображается Редактор (TipTap) или Форма Q&A (в зависимости от текущего шага)."
Форма Q&A содержит цитаты, которые надо подсвечивать в редакторе, т.е. нужно показывать и вопросы, и исходный текст, к которому поставлены вопросы, чтобы видеть вопросы в контексте. Таким образом или только редактор, или редактор и форма Q&A.
кроме того, В центральной части должна быть показана панель таймлайна, на котором отображается таймлайн этапа. И где-то еще должен быть таймлайн всего проекта.
Таймлайн интерактивный, с возможностью выбрать модель и системный промпт для ИИ.
Может быть для этапа сделать вертикальный таймлайн, и поместить его в правую панель, таймлайн всего проекта (по этапам) поместить сверху в центральной области?





Отличное замечание по UX. Контекст критически важен при ответах на вопросы, а навигация по процессу должна быть всегда перед глазами.


Перерабатываю структуру интерфейса с учетом двух таймлайнов и Split-View режима.



Раздел 5. Функциональные Требования (UI/UX) — Исправленная версия

5.1. Общая Компоновка (Layout)

1. Верхняя панель (Project Timeline):


Расположена над центральной областью.
Горизонтальный степпер: Отображает этапы проекта (напр.
1. Бриф
->
2. Бизнес-требования
->
3. Архитектура
).
Показывает текущий активный этап.
Позволяет переключаться между завершенными этапами для просмотра истории.

2. Центральная область (Рабочая зона):


Основное пространство для контента.
Режимы отображения:
Full Editor: (Для ввода данных, ручной правки и финального просмотра). Редактор TipTap на всю ширину.
Split View (Q&A Mode): (Для этапа уточнения).
Слева (60%): Редактор с исходным текстом (Read-only). Цитаты, к которым есть вопросы, подсвечиваются цветом.
Справа (40%): Панель с формой вопросов и ответов. При клике на вопрос — редактор скроллится к соответствующей цитате.

3. Правая панель (Stage Control & Context):


Вкладка "Процесс" (Stage Timeline):
Вертикальный таймлайн: Отображает шаги текущего этапа (напр.
● Анализ
->
○ Уточнение
->
○ Генерация
).
Интерактивность:
Показывает статус каждого шага (Выполнено / В работе / Ожидание).
Для предстоящих шагов (напр. "Генерация") позволяет выбрать Модель и Промпт через выпадающие списки прямо в карточке шага.
Вкладка "Контекст":
Список загруженных файлов.
Token Meter (индикатор заполненности контекста).

4. Левая панель (Навигация):


Список проектов, Настройки, Профиль (как описывали ранее).

5.2. Интерфейс Q&A (Split View)

Синхронизация:
Вопрос в правой панели связан с фрагментом текста в левом редакторе.
Hover-эффект: Наведение на вопрос подсвечивает текст ярче.
Форма:
Карточки вопросов идут списком.
Поля ввода ответов находятся прямо под текстом вопроса.
Валидация ошибок (от Quality Gate) отображается внутри карточки вопроса.

5.3. Блочный Редактор (TipTap)

(Без изменений: Блоки, ID, Контейнеры)


5.4. Настройки Проекта

(Без изменений: Workflow Drag&Drop, Team Invites)


5.5. Админка и Профиль

(Без изменений)



Теперь компоновка верна? Утверждаем Раздел 5 и переходим к Разделу 6 (Бизнес-процессы n8n)?

уточнение:

Справа (40%): Панель с формой вопросов и ответов. При клике на вопрос — редактор скроллится к соответствующей цитате. - автоскролл должен быть отключаемым, чтобы если пользователь просто случайно ткнет в другой вопрос, текст не проскроллился и пользователь не потерял контекст. Т.е. должен быть переключатель "Автоскролл", и подсказка "При клике на вопрос автоматически будет показан фрагмент текста по этому вопросу", а рядом с вопросом тогда кнопка "Показать в контексте", которая появляется при отключении автоскролла.
С учетом этого уточнения выведи Раздел 5 без сокращений, полностью.






Принято. Это важное уточнение для юзабилити, чтобы интерфейс не "прыгал" против воли пользователя.


Вывожу Раздел 5 полностью, со всеми деталями.



Раздел 5. Функциональные Требования (UI/UX)

Интерфейс системы спроектирован для обеспечения фокуса на работе с требованиями, предоставляя контекстную помощь ИИ именно там, где она нужна.


5.1. Общая Компоновка (Layout)

1. Верхняя панель (Project Timeline):


Расположена над центральной областью.
Представляет собой Горизонтальный степпер, отображающий жизненный цикл проекта (напр.
1. Бриф
->
2. Бизнес-требования
->
3. Архитектура
).
Показывает текущий активный этап.
Позволяет кликнуть на завершенные этапы для просмотра их результатов (в режиме Read-only).

2. Центральная область (Рабочая зона):


Занимает основное пространство экрана.
Режимы отображения:
Full Editor: (Используется на шагах Ввода, Ручной правки и Финализации). Редактор TipTap занимает всю ширину рабочей зоны.
Split View (Q&A Mode): (Используется на шаге Уточнения). Экран делится вертикально:
Слева (60%): Редактор с исходным текстом (Read-only). Цитаты, вызвавшие вопросы ИИ, подсвечены фоновым цветом (Highlight).
Справа (40%): Панель с формой вопросов и ответов.

3. Правая панель (Stage Control & Context):


Сворачиваемая боковая панель.
Вкладка "Процесс" (Stage Timeline):
Вертикальный таймлайн: Отображает последовательность шагов внутри текущего этапа (напр.
● Анализ
->
○ Уточнение
->
○ Генерация
).
Статусы: Визуальная индикация (Галочка = Выполнено, Спиннер = В работе, Серый круг = Ожидание).
Настройки шага: Для предстоящих шагов (которые еще не запущены) отображаются выпадающие списки для выбора Модели ИИ и Системного Промпта.
Вкладка "Контекст":
Список загруженных файлов.
Token Meter (индикатор заполненности контекстного окна).

4. Левая панель (Навигация):


Список доступных проектов.
Кнопка перехода в Настройки проекта.
Профиль пользователя.

5.2. Интерфейс Q&A (Split View)

Реализует взаимодействие пользователя с вопросами ИИ.


Связь Вопрос-Текст:
Каждый вопрос в правой части привязан к конкретному фрагменту текста в левом редакторе.
Hover-эффект: При наведении курсора на карточку вопроса, соответствующий фрагмент текста слева подсвечивается ярче.
Управление Навигацией (Скролл):
Переключатель "Автоскролл": Тоггл в заголовке панели вопросов.
ВКЛ (Default): Клик на карточку вопроса плавно прокручивает левый редактор к цитате.
ВЫКЛ: Клик на вопрос не вызывает прокрутку (чтобы не терять текущую позицию чтения).
Кнопка "Показать в контексте": Появляется рядом с вопросом только если Автоскролл выключен. При нажатии принудительно скроллит к цитате.
Форма Ответов:
Поле ввода ответа находится внутри карточки вопроса.
Валидация: Ошибки от Quality Gate (напр. "Ответ неполный") отображаются красным текстом под полем ввода.
Кнопки действий: "Отправить ответы" (блокируется при ошибках) и "Force Submit" (скрыта в меню "Дополнительно").

5.3. Блочный Редактор (TipTap)

Основной инструмент для работы с контентом требований.


Структура:
Поддержка вложенности (Nested Blocks) для реализации концепции "Требование-Контейнер".
Стандартное форматирование: Заголовки, Списки, Таблицы, Жирный/Курсив.
Идентификация:
Уникальные ID требований (напр.
BR-001
) отображаются визуально рядом с блоком (на полях или как Badge).
ID генерируются автоматически при создании нового блока-контейнера.
Drag & Drop:
Возможность менять порядок требований перетаскиванием за "ручку" (Handle) слева от блока.

5.4. Панель "Файлы и Контекст"

Upload Zone: Область для перетаскивания файлов (PDF, DOCX, TXT).
Token Meter:
Визуальная шкала (Прогресс-бар), показывающая процент использования контекстного окна выбранной модели.
Цветовая индикация: Зеленый (<80%), Желтый (80-95%), Красный (>100% — блокировка запуска).
Управление файлами: Список с возможностью удаления ошибочно загруженных файлов.

5.5. Настройки Проекта (Settings)

Вкладка "Workflow":
Список этапов в виде карточек.
Drag & Drop для изменения порядка этапов.
Кнопка "Добавить этап": Открывает библиотеку шаблонов этапов.
Кнопка "Удалить этап": Требует подтверждения, если этап содержит данные.
Вкладка "Команда":
Таблица участников: Email, Роль (
Editor
/
Reader
), Статус приглашения.
Кнопка "Пригласить": Форма ввода Email и выбора Роли.

5.6. Админка и Профиль

Профиль пользователя:
Редактирование имени.
Смена пароля (Текущий -> Новый -> Подтверждение).
Панель Администратора (Super Admin):
Таблица всех пользователей системы.
Фильтры по Email и Статусу.
Действия: "Заблокировать доступ", "Разблокировать", "Сбросить пароль" (ручная установка временного пароля).


Раздел 5 утвержден? Переходим к Разделу 6 (Бизнес-процессы n8n)?

Утвержден. Пожалуйста, выведи раздел 6.






Принято. Переходим к описанию бэкенд-логики, реализованной на n8n.



Раздел 6. Бизнес-процессы (n8n Workflows)

Архитектура бэкенда построена на базе n8n, который выполняет роль API Gateway и Оркестратора. Все запросы от Frontend поступают на Webhook-ноды n8n.


6.1. API Gateway и Роутинг

Единая точка входа (или набор точек по доменам функциональности), распределяющая нагрузку.


Main Router Workflow:
Trigger:
POST /api/v1/*
Auth Middleware: Проверка JWT токена (кроме эндпоинтов
/login
,
/register
). Если токен невалиден — возврат 401.
Route Switch: На основе URL перенаправляет запрос в соответствующий Sub-workflow:
/auth/*
-> Auth Workflow
/projects/*
-> Project Workflow
/ai/*
-> AI Engine Workflow
/files/*
-> File Workflow

6.2. Аутентификация и Пользователи (Auth Workflow)

POST /auth/register:
Проверка уникальности Email в ArangoDB.
Хеширование пароля (Argon2/Bcrypt).
Создание документа в коллекции
Users
.
Генерация JWT и возврат клиенту.
POST /auth/login:
Поиск пользователя по Email.
Сверка хеша пароля.
Если ОК -> Генерация JWT.
POST /auth/invite:
Проверка прав (Requester должен быть Owner проекта).
Создание документа в
Invites
(генерация токена).
Отправка Email (через SMTP Node / SendGrid) со ссылкой.
POST /auth/accept-invite:
Поиск инвайта по токену.
Создание ребра
MemberOf
(связь User -> Project).
Удаление/гашение инвайта.

6.3. Управление Данными (Project Workflow)

CRUD Projects & Stages:
Стандартные операции чтения/записи в ArangoDB.
Особенность: При создании проекта автоматически создается дефолтный набор этапов (Stages) из шаблона.
Особенность: При удалении этапа происходит пересчет поля
order
у соседних этапов.
CRUD Documents:
Чтение/Запись документов и их атомарных требований.
Patch Requirement: Обновление контента конкретного блока (от TipTap).

6.4. AI Engine (Ядро Системы)

Самый сложный процесс, реализующий логику из Раздела 4.


POST /ai/process-step:

Вход:
project_id
,
stage_id
,
step_id
,
user_input
(ответы или текст).
Logic:
Загружает конфигурацию шага из БД (
Stages.steps
).
Определяет тип шага (
step.type
).
Загружает соответствующий Промпт и Модель.
Switch by Type:
ambiguity_loop
: Вызывает Sub-workflow анализа или проверки ответов.
simple_generation
: Собирает контекст -> Вызывает LLM -> Парсит JSON -> Пишет в БД.
compliance_check
: Вызывает LLM сравнения -> Возвращает Diff Report.
Logging: Записывает метаданные запроса (токены, модель, промпт) в коллекцию
Iterations
.
Sub-workflow: Context Builder:

Функция для сборки контекста.
Собирает: Текст текущего этапа + Текст файлов + Результаты предыдущих этапов (по цепочке
DocLink
).
Обрезает контекст, если он превышает лимит модели (стратегия "сначала новые" или "сначала важные").

6.5. Обработка Файлов (File Workflow)

POST /files/upload:
Вход: Binary Data (Multipart Form).
Processing:
Сохранение файла (на диск или S3).
Text Extraction: Использование утилит (напр.
pdf-parse
,
mammoth
для docx) для извлечения текста.
Token Count: Подсчет токенов в извлеченном тексте.
DB: Создание документа в
Attachments
с полем
parsed_text
.
Выход: ID файла и размер в токенах (для обновления UI).


Раздел 6 утвержден? Переходим к финальному Разделу 7 (Roadmap)?

а MCP и RAG тут не нужно, в 6 этапе?









Отличный вопрос.


Про RAG (Retrieval-Augmented Generation):
Да, вы абсолютно правы. В пункте 6.4 (Context Builder) я описал простую сборку контекста ("взять всё и сложить"), но для больших проектов этого недостаточно — мы упремся в лимиты токенов.
Нужно добавить RAG: Использовать возможности ArangoDB (Vector Search) для умного поиска релевантных кусков текста из прошлых этапов, вместо того чтобы грузить всё подряд.


Про MCP (Model Context Protocol):
MCP — это стандарт для подключения ИИ к внешним данным. В нашей архитектуре роль "коннектора" выполняет n8n. Он сам ходит в базу, парсит файлы и готовит JSON для ИИ. Внедрение MCP сейчас может усложнить MVP, так как n8n уже отлично справляется с этой задачей через свои нативные интеграции (LangChain ноды).
Однако, если вы планируете в будущем подключать внешние источники (Jira, Confluence, Slack) без написания кода, то архитектуру можно подготовить под это.


Предлагаю дополнить Раздел 6 блоком про RAG. (MCP пока оставим за скобками, чтобы не перегружать MVP, если вы не против).


Вношу изменения в Раздел 6.



Раздел 6. Бизнес-процессы (n8n Workflows) — Дополнено RAG

6.1, 6.2, 6.3

(Без изменений)


6.4. AI Engine и RAG (Ядро Системы)

POST /ai/process-step: (Логика маршрутизации шагов остается прежней)

Sub-workflow: Context Builder (RAG Strategy): Отвечает за формирование промпта, который влезет в лимиты модели.

Input: Текущий запрос пользователя + ID этапа.
Retrieval (Поиск):
Short-term Memory: Берет текущий черновик документа и ответы Q&A (всегда включаются полностью).
Long-term Memory (RAG): Если объем предыдущих этапов велик, n8n делает векторный поиск (Vector Search) в ArangoDB, находя только те требования из прошлых документов, которые семантически связаны с текущим шагом.
Assembly: Собирает финальный промпт:
System Prompt
+
RAG Context
+
User Input
.
Token Check: Финальная проверка лимитов перед отправкой.

6.5. Обработка Файлов (File Workflow)

POST /files/upload:
Сохранение и парсинг текста.
Embedding Generation: (Добавлено). n8n отправляет текст в OpenAI Embeddings (или локальную модель).
Vector Store: Сохраняет векторное представление текста в ArangoDB (для работы RAG).


Теперь с учетом RAG раздел 6 утвержден? Переходим к Разделу 7 (Roadmap)?

Выведи пожалуйста полный текст раздела 6 без сокращений.






Принято. Вывожу Раздел 6 полностью, включая логику RAG и обработки файлов.



Раздел 6. Бизнес-процессы (n8n Workflows)

Архитектура бэкенда построена на базе платформы автоматизации n8n, которая выполняет роль API Gateway, Оркестратора бизнес-логики и Интегратора ИИ-сервисов. Все запросы от Frontend поступают на Webhook-ноды n8n.


6.1. API Gateway и Роутинг

Единая точка входа для всех клиентских запросов.


Main Router Workflow:
Trigger:
POST /api/v1/*
(Catch-all webhook).
Auth Middleware:
Извлекает
Bearer Token
из заголовка
Authorization
.
Валидирует JWT (проверка подписи и срока действия).
Если токен невалиден (и запрос не на
/login
/
/register
) — возвращает статус
401 Unauthorized
.
Если валиден — извлекает
user_id
и передает дальше.
Route Switch: На основе URL перенаправляет запрос в соответствующий Sub-workflow:
/auth/*
-> Auth Workflow
/projects/*
-> Project Workflow
/ai/*
-> AI Engine Workflow
/files/*
-> File Workflow

6.2. Аутентификация и Пользователи (Auth Workflow)

Обрабатывает регистрацию, вход и управление доступом.


POST /auth/register:
Проверяет уникальность Email в коллекции
Users
(ArangoDB).
Хеширует пароль (используя ноду Crypto / Argon2).
Создает новый документ пользователя в БД.
Генерирует JWT токен.
Возвращает токен и профиль пользователя.
POST /auth/login:
Ищет пользователя по Email.
Сверяет хеш пароля.
Если успешно — генерирует и возвращает JWT.
POST /auth/invite:
Проверяет права (Requester должен иметь роль
owner
в проекте).
Создает документ в коллекции
Invites
(генерирует уникальный токен).
Отправляет Email приглашенному (через SMTP или API почтового сервиса) со ссылкой активации.
POST /auth/accept-invite:
Ищет инвайт по токену.
Проверяет срок действия.
Создает ребро
MemberOf
между пользователем и проектом.
Удаляет использованный инвайт.

6.3. Управление Данными (Project Workflow)

CRUD операции для основных сущностей системы.


CRUD Projects & Stages:
Create Project: Создает проект и автоматически генерирует дефолтный набор этапов (Stages) на основе системного шаблона.
Update Stage Order: При изменении порядка этапов (Drag&Drop) обновляет поле
order
у всех затронутых этапов.
Delete Stage: Проверяет наличие данных. Если пусто — удаляет. Если есть данные — возвращает ошибку или требует флага
force
.
CRUD Documents:
Get Document: Возвращает документ и дерево его требований (Requirements), собранное через графовый запрос (AQL Traversal).
Patch Requirement: Обновляет контент конкретного блока (получая JSON от TipTap). Обновляет метаданные
updated_at
.

6.4. AI Engine и RAG (Ядро Системы)

Центральный процесс, управляющий взаимодействием с LLM.


POST /ai/process-step:

Входные данные:
project_id
,
stage_id
,
step_id
,
user_input
(ответы на вопросы или исходный текст).
Step Loader: Загружает конфигурацию текущего шага из массива
steps
коллекции
Stages
.
Type Switch: В зависимости от
step.type
выбирает ветку логики:
ambiguity_loop
:
Вызывает Sub-workflow
Context Builder
.
Отправляет запрос в LLM (Анализ).
Если есть вопросы — возвращает JSON клиенту.
Если пришли ответы — запускает LLM (Проверка качества).
simple_generation
:
Вызывает Sub-workflow
Context Builder
.
Отправляет запрос в LLM (Генерация).
Парсит ответ и создает структуру документа в БД (
Documents
+
Requirements
).
compliance_check
:
Загружает исходный текст и сгенерированный результат.
Отправляет в LLM для сравнения.
Возвращает Diff Report.
Logging: Записывает полную информацию о транзакции (Промпт, Модель, Токены, Результат) в коллекцию
Iterations
.
Sub-workflow: Context Builder (RAG Strategy):

Отвечает за подготовку контекста для LLM.
Retrieval (Сбор данных):
Текущий контекст: Берет введенный текст и файлы текущего этапа.
Исторический контекст (RAG): Если объем предыдущих документов велик, выполняет Векторный поиск (Vector Search) в ArangoDB. Находит топ-N фрагментов требований из прошлых этапов, релевантных текущей задаче.
Assembly: Объединяет
System Prompt
+
RAG Context
+
User Input
.
Token Check: Проверяет суммарное количество токенов. Если превышает лимит модели — обрезает наименее важную часть контекста (или возвращает ошибку).

6.5. Обработка Файлов (File Workflow)

POST /files/upload:
Input: Binary Data (Multipart Form).
Processing:
Сохраняет файл (в S3 или локальную папку).
Text Extraction: Извлекает текст из PDF/DOCX (используя библиотеки типа
pdf-parse
).
Embedding Generation: Генерирует векторные представления (Embeddings) для извлеченного текста (через OpenAI API или локальную модель).
Database:
Создает документ в
Attachments
с полями
parsed_text
и
size_tokens
.
Сохраняет векторы в индекс ArangoDB (для работы RAG).
Output: Возвращает ID файла и его размер в токенах для отображения в UI.


Раздел 6 утвержден? Переходим к финальному Разделу 7 (Roadmap)?

Token Check: Проверяет суммарное количество токенов. Если превышает лимит модели — обрезает наименее важную часть контекста (или возвращает ошибку).
НАдо спрашивать у пользователя, что сделать в случае превышения контекста: использовать RAG, сократить контекст (пользователь это делает руками) или остановиться (?)


С учетом этого уточнения выведи полный текст раздела 6, без сокращений.







Принято. Автоматическое обрезание контекста без ведома пользователя — плохая практика, так как могут пропасть важные детали. Передаем контроль пользователю.


Вывожу Раздел 6 полностью с обновленной логикой проверки токенов.



Раздел 6. Бизнес-процессы (n8n Workflows)

Архитектура бэкенда построена на базе платформы автоматизации n8n, которая выполняет роль API Gateway, Оркестратора бизнес-логики и Интегратора ИИ-сервисов. Все запросы от Frontend поступают на Webhook-ноды n8n.


6.1. API Gateway и Роутинг

Единая точка входа для всех клиентских запросов.


Main Router Workflow:
Trigger:
POST /api/v1/*
(Catch-all webhook).
Auth Middleware:
Извлекает
Bearer Token
из заголовка
Authorization
.
Валидирует JWT (проверка подписи и срока действия).
Если токен невалиден (и запрос не на
/login
/
/register
) — возвращает статус
401 Unauthorized
.
Если валиден — извлекает
user_id
и передает дальше.
Route Switch: На основе URL перенаправляет запрос в соответствующий Sub-workflow:
/auth/*
-> Auth Workflow
/projects/*
-> Project Workflow
/ai/*
-> AI Engine Workflow
/files/*
-> File Workflow

6.2. Аутентификация и Пользователи (Auth Workflow)

Обрабатывает регистрацию, вход и управление доступом.


POST /auth/register:
Проверяет уникальность Email в коллекции
Users
(ArangoDB).
Хеширует пароль (используя ноду Crypto / Argon2).
Создает новый документ пользователя в БД.
Генерирует JWT токен.
Возвращает токен и профиль пользователя.
POST /auth/login:
Ищет пользователя по Email.
Сверяет хеш пароля.
Если успешно — генерирует и возвращает JWT.
POST /auth/invite:
Проверяет права (Requester должен иметь роль
owner
в проекте).
Создает документ в коллекции
Invites
(генерирует уникальный токен).
Отправляет Email приглашенному (через SMTP или API почтового сервиса) со ссылкой активации.
POST /auth/accept-invite:
Ищет инвайт по токену.
Проверяет срок действия.
Создает ребро
MemberOf
между пользователем и проектом.
Удаляет использованный инвайт.

6.3. Управление Данными (Project Workflow)

CRUD операции для основных сущностей системы.


CRUD Projects & Stages:
Create Project: Создает проект и автоматически генерирует дефолтный набор этапов (Stages) на основе системного шаблона.
Update Stage Order: При изменении порядка этапов (Drag&Drop) обновляет поле
order
у всех затронутых этапов.
Delete Stage: Проверяет наличие данных. Если пусто — удаляет. Если есть данные — возвращает ошибку или требует флага
force
.
CRUD Documents:
Get Document: Возвращает документ и дерево его требований (Requirements), собранное через графовый запрос (AQL Traversal).
Patch Requirement: Обновляет контент конкретного блока (получая JSON от TipTap). Обновляет метаданные
updated_at
.

6.4. AI Engine и RAG (Ядро Системы)

Центральный процесс, управляющий взаимодействием с LLM.


POST /ai/process-step:

Входные данные:
project_id
,
stage_id
,
step_id
,
user_input
,
context_strategy
(параметр, выбранный пользователем:
full
или
rag
).
Step Loader: Загружает конфигурацию текущего шага из массива
steps
коллекции
Stages
.
Context Build & Check: Вызывает Sub-workflow
Context Builder
.
Если вернулась ошибка лимита: Возвращает на Frontend статус
409 Conflict
с данными о превышении, предлагая пользователю выбор.
Type Switch: Если контекст в порядке, выбирает ветку логики в зависимости от
step.type
:
ambiguity_loop
: Анализ неопределенностей или проверка ответов.
simple_generation
: Генерация документа и сохранение в БД.
compliance_check
: Сравнение исходника и результата.
Logging: Записывает транзакцию в
Iterations
.
Sub-workflow: Context Builder (Interactive Strategy):

Assembly: Собирает полный контекст (Текст + Файлы + История).
Token Calculation: Считает точное количество токенов (через библиотеку
tiktoken
в Function Node).
Limit Check: Сравнивает с
context_window
модели.
Decision Logic:
Case A (Превышение): Возвращает ошибку
TokenLimitExceeded
.
Frontend Action: Показывает модальное окно: "Контекст переполнен (150%). Выберите действие: 1) Включить RAG (авто-сжатие), 2) Сократить вручную, 3) Отмена".
Case B (Норма или
context_strategy='rag'
):
Если выбран режим
rag
(или пользователь согласился на него): Выполняет Vector Search в ArangoDB, отбирая только релевантные фрагменты.
Если режим
full
: Оставляет контекст как есть.
Output: Готовый промпт для отправки в LLM.

6.5. Обработка Файлов (File Workflow)

POST /files/upload:
Input: Binary Data (Multipart Form).
Processing:
Сохраняет файл (в S3 или локальную папку).
Text Extraction: Извлекает текст из PDF/DOCX (используя библиотеки типа
pdf-parse
).
Embedding Generation: Генерирует векторные представления (Embeddings) для извлеченного текста (через OpenAI API или локальную модель).
Database:
Создает документ в
Attachments
с полями
parsed_text
и
size_tokens
.
Сохраняет векторы в индекс ArangoDB (для работы RAG).
Output: Возвращает ID файла и его размер в токенах для отображения в UI.


Раздел 6 утвержден? Переходим к финальному Разделу 7 (Roadmap)?

ты пишешь:

Сохраняет векторы в индекс ArangoDB (для работы RAG).
а ArangoDB может быть векторной базой?






Да, ArangoDB — это полноценная векторная база данных (начиная с версии 3.10).


Как это работает:

Вы сохраняете вектор (массив чисел, например
[0.12, -0.5, ...]
) как обычное поле в документе.
В ArangoDB создается специальный тип индекса — ArangoSearch View с поддержкой векторного поиска (или прямой Vector Index в новых версиях).
Вы можете выполнять AQL-запросы, которые комбинируют:
Графовый поиск (найти связи).
Фильтрацию по метаданным (найти документы проекта X).
Векторную близость (найти похожие по смыслу тексты).

Почему это круто для нашего проекта:
Нам не нужно поднимать отдельную базу (типа Pinecone, Milvus или Qdrant) только для векторов. Мы храним всё (пользователей, графы требований и векторы для RAG) в одной ArangoDB. Это упрощает инфраструктуру (Docker Compose) и поддержку.


Переходим к финальному Разделу 7 (Roadmap)?

Да, переходим к разделу 7







Отлично. Финализируем описание планом реализации.



Раздел 7. Roadmap Реализации

План разбит на этапы с нарастанием функциональности, от базового прототипа до полноценного SaaS-продукта.


Этап 1: MVP Core (Основа и Логика)

Цель: Получить работающий цикл "Анализ -> Уточнение -> Генерация" для одного пользователя.


Инфраструктура:
Настройка
Docker Compose
(ArangoDB + n8n).
Базовая настройка схем БД (коллекции
Users
,
Projects
,
Stages
,
Documents
).
Backend (n8n):
Реализация Workflow авторизации (Login/Register).
Реализация Workflow AI Engine (базовая версия: Ambiguity Check + Simple Generation).
Frontend:
Каркас приложения (React + Router).
Страница создания проекта.
Интерфейс Q&A: Форма с вопросами и ответами (пока без сложного Split View, просто последовательно).
Редактор: Базовый TipTap (текст, заголовки) для отображения результата.

Этап 2: Атомарность и Файлы (Editor & Context)

Цель: Внедрить ключевые фишки — блочный редактор и работу с файлами.


Backend:
Реализация File Workflow (загрузка, парсинг текста).
Доработка AI Engine: добавление шага Compliance Check (Сверка).
Frontend (Editor 2.0):
Внедрение кастомных узлов TipTap (Requirements Container).
Визуализация ID требований (
BR-001
).
Реализация Split View (синхронный скролл редактора и вопросов).
Компонент загрузки файлов с Token Meter.

Этап 3: SaaS и Гибкость (Collaboration)

Цель: Превратить инструмент в платформу для команд.


Backend:
Система инвайтов (SMTP, токены).
Ролевая модель (Middleware проверки прав
editor
/
reader
).
RAG: Внедрение векторного поиска в ArangoDB и логики обрезки контекста.
Frontend:
Настройки проекта: Drag & Drop этапов.
Управление командой (таблица участников).
Профиль пользователя.

Этап 4: Advanced Features (Масштабирование)

Цель: Улучшение UX и аналитика.


Git Export: Модуль экспорта документов в Markdown/GitLab.
Analytics:
Сбор статистики использования промптов.
Админка для управления справочниками промптов (рейтинг, категории).
Traceability:
Визуализация связей между требованиями (граф).
Автоматическая проверка "повисших" требований.


На этом формирование контекста проекта завершено.


Теперь у вас есть полный пакет документации (Разделы 1-7), который можно использовать как ТЗ для разработки или скормить в новый чат для начала кодинга конкретных модулей.


Желаете объединить все разделы в один финальный длинный текст для удобного копирования?

уточнения:

Этап 1.
Для фронтенда не надо ничего в инфраструктуре? Вроде был nginx
В базовой настройке БД не все коллекции указаны, почему? Dictionaries не нужны? Может еще какие-то коллекции нужны? ребра? Либо не описывать подробно, а сослаться на раздел 3 Архитектура данных?
Настаиваю на split view на форме Q&A - без общего текста и контекста будет сложно отвечать на вопросы. Цитату из вопроса показывать не надо, только подсвечивать ее в тексте по совпадению строк.






Принято. Справедливые замечания. Без контекста (Split View) MVP будет неюзабельным, поэтому переносим его в первый этап. И список коллекций лучше реализовать сразу полностью, чтобы не переделывать схему миграциями.


Вывожу Раздел 7 с учетом ваших требований.



Раздел 7. Roadmap Реализации

План реализации с приоритетом на создание полноценного UX (Split View) уже в первой версии.


Этап 1: MVP Core (Фундамент и Рабочий Процесс)

Цель: Реализовать полный цикл работы одного пользователя с удобным интерфейсом уточнения.


Инфраструктура:
Docker Compose:
arangodb
(База данных).
n8n
(Бэкенд/Логика).
nginx
(Веб-сервер для раздачи React-фронтенда и проксирования API).
База Данных:
Инициализация полной схемы из Раздела 3:
Создание всех Document Collections (
Users
,
Projects
,
Stages
,
Documents
,
Requirements
,
Dictionaries
,
Prompts
,
AI_Models
,
Iterations
).
Создание всех Edge Collections (
MemberOf
,
Structure
,
Traceability
,
DocLink
).
Заполнение
Dictionaries
базовыми значениями.
Backend (n8n):
Auth: Регистрация и Логин (JWT).
Project: Создание проекта и чтение структуры.
AI Engine: Реализация логики
Ambiguity Check
и
Simple Generation
.
Frontend (React):
Layout: Реализация основной компоновки (Навигация, Рабочая зона, Сайдбар).
Editor: Подключение TipTap (пока без сложных контейнеров, но с поддержкой Highlights).
Q&A Split View:
Реализация разделенного экрана.
Логика подсветки текста в редакторе по совпадению с вопросом.
Форма ответов (без цитирования в карточке, только вопрос и инпут).

Этап 2: Атомарность, Файлы и RAG

Цель: Углубление функциональности редактора и работа с контекстом.


Backend:
Files: Загрузка, парсинг, создание Embeddings.
RAG: Реализация логики
Context Builder
с векторным поиском.
Compliance: Добавление шага сверки (Diff Report).
Frontend:
Editor 2.0: Реализация кастомных узлов "Требование-Контейнер". Визуализация ID (
BR-001
).
Files UI: Drag & Drop зона и Token Meter (с логикой выбора стратегии при переполнении).

Этап 3: SaaS и Управление (Collaboration)

Цель: Многопользовательский режим и гибкая настройка.


Backend:
Система инвайтов (Email, Tokens).
Middleware проверки ролей (
editor
/
reader
).
CRUD для управления этапами (Drag & Drop, Add/Delete).
Frontend:
Настройки проекта (Workflow Editor).
Управление командой.
Профиль пользователя и Админка.

Этап 4: Полировка (Polish & Scale)

Цель: Вспомогательные функции.


Git Export: Генерация Markdown и коммит в репозиторий.
Analytics: Сбор статистики по промптам.
Traceability UI: Визуализация связей между требованиями.


Теперь Roadmap корректен?
Если да, я готов собрать все 7 разделов в один итоговый документ, чтобы у вас был цельный файл контекста. Сделать это?

Название проекта Coati.

================

Обновляем логику создания проекта (n8n) - Arango: Create Project мне не нравится хардкод в запросе и упрощение, не будем считать, что бриф уже есть, наоборот, создаем проект, чтобы проработать бриф, пользователь будет его вставлять.
Создавать проект нужно так, чтобы пользователь выбрал, что это будет за этап, и создавать только один этап при создании проекта. Пользователь выберет тип этапа, выберет модель ИИ из возможных значений в БД, а вот внутри этапа пусть будут наборы шагов.
В нашем случае
шаг 1: ввод текста, отправка ИИ для проверки на неопределенность (в интерфейсе только текстовый редактор).
Системный промпт должен определить задачу (найди неопределенности) и задать формат вывода (ИИ должен выдать вопросы сразу в формате JSON) - и нужна проверка, соответствует ли ответ ИИ формату, чтобы можно было загрузить вопросы в форму для ввода ответов.
шаг 2: ответы на вопросы, проверка качества ответов (в интерфейсе текстовый редактор + форма ответов на вопросы). Системный промпт должен поставить задачу на проверку качества ответов, и определить формат ответа, чтобы в случае плохого качества пришел JSON, который сразу можно было бы положить в форму для ответа на вопросы и показать замечания ИИ к ответам на вопросы.
шаг 3: генерация уточненного текста (старый текст + вопросы + ответы на вопросы) (полностью на бэкенде), но перед отправкой на этот этап должна быть возможность выбрать модель и системный промпт, который ставит задачу и определяет формат ответа. Пользовательский промпт делать не будем, пусть им станет текст исходный текст, вопросы и ответы.
шаг 4: сравнение версий пользователем (старый текст - новый текст) (в интерфейсе 2 текстовых редактора: старый текст (только чтение) новый текст (правка). Если ОК - пользователь сохраняет итоговый текст в БД. Все старые варианты текста должны быть доступны, если пользователь кликнет по шагу этапа в вертикальном таймлайне, должна открыться форма с данными этого этапа (что пользователь отправил). Если пользователь не дописал и закрыл, то нужно сохранить все данные форм - напиши, как это лучше сделать.

Этот набор шагов надо сделать
Учти, что используемые сейчас модели не принимают на вход файлы, только текст.

===============

1. При создании проекта не надо сразу добавлять этапы. Это пока просто пустой проект. Если проект пустой, и в него не добавлено ни одного этапа, то он и должен оставаться пустым. Пользователь открывает пустой проект, и система должна предложить ему добавить этап и предложить выбрать этап из ранее настроенных шаблонов. Наш шаблон как раз и предложим (нужно его краткое описание сформировать в интерфейсе). Для начала можно сделать 2 одинаковых шаблона этапа но с разными названиями шагов (чтобы было из чего выбрать).
2. Описание формата ответа может быть вынести из системного промпта, и формировать его в соответствии с логикой форм - какой формат надо получить, такой и прикладывать к системному промпту, не давать пользователю ошибиться?
3. Не увидел настроек модели в шагах этапа, а их нужно добавить.

===============

